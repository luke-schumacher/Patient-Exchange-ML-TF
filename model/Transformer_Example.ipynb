{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd40a894-2a8e-4c01-b549-7740ac309af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34293296-8eed-4664-a968-270c7f75bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory and sequence length\n",
    "data_directory = \"../data/filtered_blocks_padded/\"\n",
    "sequence_length = 36\n",
    "batch_size = 32  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f3f847f-1115-4b7b-8adc-0cf2c037328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding legend\n",
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11', 2: 'MRI_EXU_95', 3: 'MRI_FRR_18', 4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264', 6: 'MRI_FRR_3', 7: 'MRI_FRR_34', 8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100', 10: 'START', 11: 'MRI_MSR_21', 12: 'MRI_MSR_34',\n",
    "    0: 'PADDED',  # Add a padding category\n",
    "    10: 'START',  # Start token\n",
    "    9: 'END'      # End token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "351a05e4-faca-4f7d-9155-696a39e6cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, sequence_length):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    file_count = 0  # Track the number of files processed\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_count += 1\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            inputs = df['sourceID'].values\n",
    "            targets = df['sourceID'].shift(-1).fillna(0).values  # Shift by 1 and replace NaN with 0\n",
    "\n",
    "            inputs = inputs.astype(int)\n",
    "            targets = targets.astype(int)\n",
    "\n",
    "            input_sequences = []\n",
    "            target_sequences = []\n",
    "\n",
    "            # Pad sequences shorter than sequence_length\n",
    "            for i in range(len(inputs) - sequence_length + 1):\n",
    "                input_sequences.append(inputs[i:i + sequence_length])\n",
    "                target_sequences.append(targets[i:i + sequence_length])\n",
    "\n",
    "            inputs_list.append(np.array(input_sequences))\n",
    "            targets_list.append(np.array(target_sequences))\n",
    "    \n",
    "    # Combine all the sequences from all blocks\n",
    "    inputs = np.concatenate(inputs_list, axis=0)\n",
    "    targets = np.concatenate(targets_list, axis=0)\n",
    "\n",
    "    print(f\"Total files processed: {file_count}\")\n",
    "    print(f\"Combined inputs shape: {inputs.shape}\")\n",
    "    print(f\"Combined targets shape: {targets.shape}\")\n",
    "\n",
    "    return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "18e4870b-c255-451c-92a5-036debe1c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 326\n",
      "Combined inputs shape: (326, 36)\n",
      "Combined targets shape: (326, 36)\n",
      "Loaded dataset with inputs shape (326, 36) and targets shape (326, 36)\n"
     ]
    }
   ],
   "source": [
    "# Load data from the directory\n",
    "inputs, targets = load_data(data_directory, sequence_length)\n",
    "print(f\"Loaded dataset with inputs shape {inputs.shape} and targets shape {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb974844-ac84-49db-b1b1-1cc17c7c3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "dataset = dataset.batch(batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e80642d8-468f-4300-94cb-50e9bdbf5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model Implementation\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(sequence_length, d_model)\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "\n",
    "        # Apply sine to even indices in the array\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # Apply cosine to odd indices in the array\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b82aa4da-4694-4b3b-a0d0-126200c6b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed7bb374-8bfd-439d-aba8-e4795902caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dcc78ab8-028d-4cc4-92b5-1a5f223aca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer_model(num_classes, sequence_length, embedding_dim=64, num_heads=4, ff_dim=128, num_blocks=4):\n",
    "    print(f\"Creating Transformer Model with:\")\n",
    "    print(f\"- Vocabulary size: {num_classes}\")\n",
    "    print(f\"- Sequence length: {sequence_length}\")\n",
    "    print(f\"- Embedding dimension: {embedding_dim}\")\n",
    "    print(f\"- Number of heads: {num_heads}\")\n",
    "    print(f\"- FFN dimension: {ff_dim}\")\n",
    "    print(f\"- Number of blocks: {num_blocks}\")\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(sequence_length,))\n",
    "    embedding = tf.keras.layers.Embedding(num_classes, embedding_dim)(inputs)\n",
    "    \n",
    "    x = embedding\n",
    "    for _ in range(num_blocks):\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(x, x)\n",
    "        attention_output = tf.keras.layers.LayerNormalization()(attention_output + x)\n",
    "        \n",
    "        ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attention_output)\n",
    "        ffn_output = tf.keras.layers.Dense(embedding_dim)(ffn_output)\n",
    "        x = tf.keras.layers.LayerNormalization()(ffn_output + attention_output)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(num_classes)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4f879c18-ad30-4de9-9424-180cdc11321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "vocab_size = np.max(inputs) + 1  # Number of unique sourceIDs\n",
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f118e251-fed7-4d8e-b316-7a5a36c92658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Transformer Model with:\n",
      "- Vocabulary size: 13\n",
      "- Sequence length: 36\n",
      "- Embedding dimension: 32\n",
      "- Number of heads: 2\n",
      "- FFN dimension: 32\n",
      "- Number of blocks: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">          Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)               │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">8,416</span> │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                          │                  │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                          │                  │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_36        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ layer_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dense_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                          │                  │ layer_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_37        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">8,416</span> │ layer_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                          │                  │ layer_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                          │                  │ layer_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_38        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ layer_normalization_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dense_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                          │                  │ layer_normalization_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_39        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">8,416</span> │ layer_normalization_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                          │                  │ layer_normalization_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                          │                  │ layer_normalization_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_40        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ layer_normalization_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                          │                  │ layer_normalization_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_41        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">8,416</span> │ layer_normalization_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                          │                  │ layer_normalization_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                          │                  │ layer_normalization_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_42        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ layer_normalization_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                          │                  │ layer_normalization_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_43        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │ layer_normalization_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└───────────────────────────────┴──────────────────────────┴──────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)               │                \u001b[38;5;34m0\u001b[0m │ -                         │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │              \u001b[38;5;34m416\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m8,416\u001b[0m │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                          │                  │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_24 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ multi_head_attention_18[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                          │                  │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_36        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ layer_normalization_36[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ dense_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_25 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                          │                  │ layer_normalization_36[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_37        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m8,416\u001b[0m │ layer_normalization_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                          │                  │ layer_normalization_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_26 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ multi_head_attention_19[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                          │                  │ layer_normalization_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_38        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ layer_normalization_38[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ dense_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_27 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                          │                  │ layer_normalization_38[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_39        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m8,416\u001b[0m │ layer_normalization_39[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                          │                  │ layer_normalization_39[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_28 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ multi_head_attention_20[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                          │                  │ layer_normalization_39[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_40        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ layer_normalization_40[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                          │                  │ layer_normalization_40[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_41        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ multi_head_attention_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m8,416\u001b[0m │ layer_normalization_41[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                          │                  │ layer_normalization_41[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ multi_head_attention_21[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                          │                  │ layer_normalization_41[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_42        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ layer_normalization_42[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │            \u001b[38;5;34m1,056\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │                \u001b[38;5;34m0\u001b[0m │ dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                          │                  │ layer_normalization_42[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ layer_normalization_43        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m64\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                          │                  │                           │\n",
       "├───────────────────────────────┼──────────────────────────┼──────────────────┼───────────────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m13\u001b[0m)           │              \u001b[38;5;34m429\u001b[0m │ layer_normalization_43[\u001b[38;5;34m0\u001b[0m… │\n",
       "└───────────────────────────────┴──────────────────────────┴──────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,469</span> (169.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,469\u001b[0m (169.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,469</span> (169.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,469\u001b[0m (169.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = create_transformer_model(vocab_size, sequence_length, embed_dim, num_heads, ff_dim)\n",
    "model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cc6f7e92-6a3a-4237-95b4-54079c5b4895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch - Input shape: (32, 36), Target shape: (32, 36)\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.5115 - loss: 1.7440\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8528 - loss: 0.5159\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8564 - loss: 0.4419\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8583 - loss: 0.4169\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8583 - loss: 0.4024\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8585 - loss: 0.3935\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8612 - loss: 0.3873\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8613 - loss: 0.3820\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8635 - loss: 0.3771\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8640 - loss: 0.3712\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 10\n",
    "for batch in dataset.take(1):  # Take one batch as an example\n",
    "    input_batch, target_batch = batch\n",
    "    print(f\"Example batch - Input shape: {input_batch.shape}, Target shape: {target_batch.shape}\")\n",
    "\n",
    "history = model.fit(dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2196693b-728d-452c-8bd8-6e214d207d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping predictions back to human-readable labels\n",
    "def map_prediction_to_label(prediction, encoding_legend):\n",
    "    mapped_labels = []\n",
    "    for token in prediction.flatten():  # Flatten to handle each token individually\n",
    "        label = encoding_legend.get(token, \"Unknown\")  # Retrieve label or mark as \"Unknown\"\n",
    "        mapped_labels.append(label)\n",
    "    return mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "630e66db-6715-41ab-8026-d3016cb0ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_sequence(input_sequence, model):\n",
    "    print(f\"Input sequence for prediction: {input_sequence}\")\n",
    "    input_sequence = np.array(input_sequence).reshape(1, -1)  # Reshape for single input\n",
    "    prediction = model.predict(input_sequence)\n",
    "    \n",
    "    print(f\"Prediction raw output shape: {prediction.shape}\")\n",
    "    \n",
    "    predicted_sequence = np.argmax(prediction, axis=-1)  # Get predicted token (sourceID)\n",
    "    print(f\"Predicted sequence (encoded): {predicted_sequence}\")\n",
    "    \n",
    "    # Mapping to human-readable labels\n",
    "    human_readable_prediction = map_prediction_to_label(predicted_sequence[0], encoding_legend)\n",
    "    print(f\"Predicted sequence (human-readable): {human_readable_prediction}\")\n",
    "    \n",
    "    return predicted_sequence, human_readable_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "98867e54-8d8b-401a-b666-cc542a8c93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence for prediction: [10  4  5  1 12  5  8  4  5  5  1  5  4  5  9  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028CC89C0360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901ms/step\n",
      "Prediction raw output shape: (1, 36, 13)\n",
      "Predicted sequence (encoded): [[4 5 1 1 8 1 9 5 1 1 1 1 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Predicted sequence (human-readable): ['MRI_FRR_257', 'MRI_FRR_264', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_MPT_1005', 'MRI_CCS_11', 'END', 'MRI_FRR_264', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_FRR_264', 'MRI_CCS_11', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED']\n",
      "Predicted sequence (encoded): [[4 5 1 1 8 1 9 5 1 1 1 1 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Predicted sequence (human-readable): ['MRI_FRR_257', 'MRI_FRR_264', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_MPT_1005', 'MRI_CCS_11', 'END', 'MRI_FRR_264', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_FRR_264', 'MRI_CCS_11', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED', 'PADDED']\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "example_input = inputs[0]  # Use the first input sequence as an example\n",
    "predicted_sequence, human_readable_sequence = predict_next_sequence(example_input, model)\n",
    "print(f\"Predicted sequence (encoded): {predicted_sequence}\")\n",
    "print(f\"Predicted sequence (human-readable): {human_readable_sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b17aa8-ea41-4011-aeb0-2643d9001dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
