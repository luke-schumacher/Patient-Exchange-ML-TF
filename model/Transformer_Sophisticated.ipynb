{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b1f1f0b-04c3-4453-8bd0-61a904b48a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca8a9abf-a16d-4db2-8f2f-0ee6f95b72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11', 2: 'MRI_EXU_95', 3: 'MRI_FRR_18', 4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264', 6: 'MRI_FRR_3', 7: 'MRI_FRR_34', 8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100', 10: 'MRI_MSR_104', 11: 'MRI_MSR_21', 12: 'MRI_MSR_34',\n",
    "    0: 'PADDED',  # Add a padding category\n",
    "    10: 'START',  # Start token\n",
    "    9: 'END'      # End token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "56f24bff-9b20-4665-8ea2-73708759b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model) // 2)) / np.float32(d_model))\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc2420f7-ac3b-4e96-99be-0596d1b12e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MultiHeadAttention Layer\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        attention = tf.reshape(attention, (batch_size, -1, self.d_model))\n",
    "        return self.dense(attention)\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3f1db13d-591f-4c18-9578-9d7e2178ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positionwise Feedforward Layer\n",
    "class PositionwiseFeedforward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dense1 = Dense(dff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Define Transformer Block\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output = self.att(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "# Define Encoder Layer\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        return x\n",
    "\n",
    "# Define Decoder Layer\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "757a4aff-c1ce-426b-ae8e-5da424d01a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # Ensure training, mask passed as keywords\n",
    "        attn_output = self.att(x, x, x, mask)  # x already contains embeddings\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "74c56e84-e57b-4f4e-ad09-919e21c802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # training and mask as keyword arguments\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b7faca35-5da9-450b-93c7-bd61ef368962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training=None, look_ahead_mask=None, padding_mask=None):  # Ensure keyword args\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, training=training, mask=look_ahead_mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8503c952-f418-4b96-9256-de552f34558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, targets, training=None, look_ahead_mask=None, padding_mask=None):\n",
    "        enc_output = self.encoder(inputs, training=training, mask=padding_mask)\n",
    "        dec_output = self.decoder(targets, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f80f098f-5cf7-4270-8635-c1d284e0d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(directory, encoding_legend):\n",
    "    all_blocks = []\n",
    "    all_source_ids = np.array(list(encoding_legend.keys())).reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(all_source_ids)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            block = pd.read_csv(file_path)\n",
    "\n",
    "            assert block.shape == (36, 5), f\"Block {filename} has an unexpected shape {block.shape}\"\n",
    "\n",
    "            source_ids = block[['sourceID']].values.reshape(-1, 1)\n",
    "            one_hot_encoded_sourceID = encoder.transform(source_ids)\n",
    "\n",
    "            # Normalize additional features\n",
    "            timediff = block[['timediff']].values\n",
    "            ptab = np.nan_to_num(block[['PTAB']].values)\n",
    "            timediff = (timediff - np.mean(timediff)) / np.std(timediff)\n",
    "            ptab = (ptab - np.mean(ptab)) / np.std(ptab)\n",
    "            body_group_from = block[['BodyGroup_from']].values\n",
    "            body_group_to = block[['BodyGroup_to']].values\n",
    "\n",
    "            # Create input block with start and end tokens\n",
    "            X_block = np.concatenate((one_hot_encoded_sourceID, timediff, ptab, body_group_from, body_group_to), axis=1)\n",
    "            all_blocks.append(X_block)\n",
    "\n",
    "    all_blocks = np.stack(all_blocks, axis=0)\n",
    "    return all_blocks, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da9a3972-344e-4087-ad19-9dbd56b5d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the 150 CSV data blocks\n",
    "data_directory = \"../data/filtered_blocks_padded/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7300fa33-e507-4ce2-a127-c650363c78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data and obtain one-hot encoding for sourceIDs\n",
    "all_blocks, encoder = preprocess_data(data_directory, encoding_legend)\n",
    "\n",
    "# Parameters for model\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "input_vocab_size = len(encoder.categories_[0])  # Number of unique sourceIDs\n",
    "target_vocab_size = input_vocab_size  # Assuming prediction is similar to input\n",
    "pe_input = 1000\n",
    "pe_target = 1000\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b6ae9a0-fb85-4416-bbef-808d5a83cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer model\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07c0efc5-d222-482f-8d7c-789ae6f4ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input (creating dummy data for testing)\n",
    "# Adjust batch size based on your data length\n",
    "batch_size = min(32, len(df) // 2)  # Ensure at least some data for batching\n",
    "max_seq_length = 36  # Adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e0137e00-3b39-4bf2-99ea-59c4544b48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy input and target sequences (for illustration)\n",
    "inputs = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=input_vocab_size)\n",
    "targets = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=target_vocab_size)\n",
    "look_ahead_mask = None\n",
    "padding_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf55e234-7c56-4ee3-bbb4-0a5b083c9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 36, 13)\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "output = transformer(inputs=inputs, targets=targets, training=True, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "print(output.shape)  # Should now work correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c6bc859b-feba-4929-80d5-28bc8033eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))  # Mask out padding tokens\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f7c812bd-387f-4556-a213-4090cc41fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded padded_block_1.csv, shape: (36, 5)\n",
      "Loaded padded_block_10.csv, shape: (36, 5)\n",
      "Loaded padded_block_100.csv, shape: (36, 5)\n",
      "Loaded padded_block_101.csv, shape: (36, 5)\n",
      "Loaded padded_block_102.csv, shape: (36, 5)\n",
      "Loaded padded_block_103.csv, shape: (36, 5)\n",
      "Loaded padded_block_104.csv, shape: (36, 5)\n",
      "Loaded padded_block_105.csv, shape: (36, 5)\n",
      "Loaded padded_block_106.csv, shape: (36, 5)\n",
      "Loaded padded_block_107.csv, shape: (36, 5)\n",
      "Loaded padded_block_108.csv, shape: (36, 5)\n",
      "Loaded padded_block_109.csv, shape: (36, 5)\n",
      "Loaded padded_block_11.csv, shape: (36, 5)\n",
      "Loaded padded_block_110.csv, shape: (36, 5)\n",
      "Loaded padded_block_111.csv, shape: (36, 5)\n",
      "Loaded padded_block_112.csv, shape: (36, 5)\n",
      "Loaded padded_block_113.csv, shape: (36, 5)\n",
      "Loaded padded_block_114.csv, shape: (36, 5)\n",
      "Loaded padded_block_115.csv, shape: (36, 5)\n",
      "Loaded padded_block_116.csv, shape: (36, 5)\n",
      "Loaded padded_block_117.csv, shape: (36, 5)\n",
      "Loaded padded_block_118.csv, shape: (36, 5)\n",
      "Loaded padded_block_119.csv, shape: (36, 5)\n",
      "Loaded padded_block_12.csv, shape: (36, 5)\n",
      "Loaded padded_block_120.csv, shape: (36, 5)\n",
      "Loaded padded_block_121.csv, shape: (36, 5)\n",
      "Loaded padded_block_122.csv, shape: (36, 5)\n",
      "Loaded padded_block_123.csv, shape: (36, 5)\n",
      "Loaded padded_block_124.csv, shape: (36, 5)\n",
      "Loaded padded_block_125.csv, shape: (36, 5)\n",
      "Loaded padded_block_126.csv, shape: (36, 5)\n",
      "Loaded padded_block_127.csv, shape: (36, 5)\n",
      "Loaded padded_block_128.csv, shape: (36, 5)\n",
      "Loaded padded_block_129.csv, shape: (36, 5)\n",
      "Loaded padded_block_13.csv, shape: (36, 5)\n",
      "Loaded padded_block_130.csv, shape: (36, 5)\n",
      "Loaded padded_block_131.csv, shape: (36, 5)\n",
      "Loaded padded_block_132.csv, shape: (36, 5)\n",
      "Loaded padded_block_133.csv, shape: (36, 5)\n",
      "Loaded padded_block_134.csv, shape: (36, 5)\n",
      "Loaded padded_block_135.csv, shape: (36, 5)\n",
      "Loaded padded_block_136.csv, shape: (36, 5)\n",
      "Loaded padded_block_137.csv, shape: (36, 5)\n",
      "Loaded padded_block_138.csv, shape: (36, 5)\n",
      "Loaded padded_block_139.csv, shape: (36, 5)\n",
      "Loaded padded_block_14.csv, shape: (36, 5)\n",
      "Loaded padded_block_140.csv, shape: (36, 5)\n",
      "Loaded padded_block_141.csv, shape: (36, 5)\n",
      "Loaded padded_block_142.csv, shape: (36, 5)\n",
      "Loaded padded_block_143.csv, shape: (36, 5)\n",
      "Loaded padded_block_144.csv, shape: (36, 5)\n",
      "Loaded padded_block_145.csv, shape: (36, 5)\n",
      "Loaded padded_block_146.csv, shape: (36, 5)\n",
      "Loaded padded_block_147.csv, shape: (36, 5)\n",
      "Loaded padded_block_148.csv, shape: (36, 5)\n",
      "Loaded padded_block_149.csv, shape: (36, 5)\n",
      "Loaded padded_block_15.csv, shape: (36, 5)\n",
      "Loaded padded_block_150.csv, shape: (36, 5)\n",
      "Loaded padded_block_16.csv, shape: (36, 5)\n",
      "Loaded padded_block_17.csv, shape: (36, 5)\n",
      "Loaded padded_block_18.csv, shape: (36, 5)\n",
      "Loaded padded_block_19.csv, shape: (36, 5)\n",
      "Loaded padded_block_2.csv, shape: (36, 5)\n",
      "Loaded padded_block_20.csv, shape: (36, 5)\n",
      "Loaded padded_block_21.csv, shape: (36, 5)\n",
      "Loaded padded_block_22.csv, shape: (36, 5)\n",
      "Loaded padded_block_23.csv, shape: (36, 5)\n",
      "Loaded padded_block_24.csv, shape: (36, 5)\n",
      "Loaded padded_block_25.csv, shape: (36, 5)\n",
      "Loaded padded_block_26.csv, shape: (36, 5)\n",
      "Loaded padded_block_27.csv, shape: (36, 5)\n",
      "Loaded padded_block_28.csv, shape: (36, 5)\n",
      "Loaded padded_block_29.csv, shape: (36, 5)\n",
      "Loaded padded_block_3.csv, shape: (36, 5)\n",
      "Loaded padded_block_30.csv, shape: (36, 5)\n",
      "Loaded padded_block_31.csv, shape: (36, 5)\n",
      "Loaded padded_block_32.csv, shape: (36, 5)\n",
      "Loaded padded_block_33.csv, shape: (36, 5)\n",
      "Loaded padded_block_34.csv, shape: (36, 5)\n",
      "Loaded padded_block_35.csv, shape: (36, 5)\n",
      "Loaded padded_block_36.csv, shape: (36, 5)\n",
      "Loaded padded_block_37.csv, shape: (36, 5)\n",
      "Loaded padded_block_38.csv, shape: (36, 5)\n",
      "Loaded padded_block_39.csv, shape: (36, 5)\n",
      "Loaded padded_block_4.csv, shape: (36, 5)\n",
      "Loaded padded_block_40.csv, shape: (36, 5)\n",
      "Loaded padded_block_41.csv, shape: (36, 5)\n",
      "Loaded padded_block_42.csv, shape: (36, 5)\n",
      "Loaded padded_block_43.csv, shape: (36, 5)\n",
      "Loaded padded_block_44.csv, shape: (36, 5)\n",
      "Loaded padded_block_45.csv, shape: (36, 5)\n",
      "Loaded padded_block_46.csv, shape: (36, 5)\n",
      "Loaded padded_block_47.csv, shape: (36, 5)\n",
      "Loaded padded_block_48.csv, shape: (36, 5)\n",
      "Loaded padded_block_49.csv, shape: (36, 5)\n",
      "Loaded padded_block_5.csv, shape: (36, 5)\n",
      "Loaded padded_block_50.csv, shape: (36, 5)\n",
      "Loaded padded_block_51.csv, shape: (36, 5)\n",
      "Loaded padded_block_52.csv, shape: (36, 5)\n",
      "Loaded padded_block_53.csv, shape: (36, 5)\n",
      "Loaded padded_block_54.csv, shape: (36, 5)\n",
      "Loaded padded_block_55.csv, shape: (36, 5)\n",
      "Loaded padded_block_56.csv, shape: (36, 5)\n",
      "Loaded padded_block_57.csv, shape: (36, 5)\n",
      "Loaded padded_block_58.csv, shape: (36, 5)\n",
      "Loaded padded_block_59.csv, shape: (36, 5)\n",
      "Loaded padded_block_6.csv, shape: (36, 5)\n",
      "Loaded padded_block_60.csv, shape: (36, 5)\n",
      "Loaded padded_block_61.csv, shape: (36, 5)\n",
      "Loaded padded_block_62.csv, shape: (36, 5)\n",
      "Loaded padded_block_63.csv, shape: (36, 5)\n",
      "Loaded padded_block_64.csv, shape: (36, 5)\n",
      "Loaded padded_block_65.csv, shape: (36, 5)\n",
      "Loaded padded_block_66.csv, shape: (36, 5)\n",
      "Loaded padded_block_67.csv, shape: (36, 5)\n",
      "Loaded padded_block_68.csv, shape: (36, 5)\n",
      "Loaded padded_block_69.csv, shape: (36, 5)\n",
      "Loaded padded_block_7.csv, shape: (36, 5)\n",
      "Loaded padded_block_70.csv, shape: (36, 5)\n",
      "Loaded padded_block_71.csv, shape: (36, 5)\n",
      "Loaded padded_block_72.csv, shape: (36, 5)\n",
      "Loaded padded_block_73.csv, shape: (36, 5)\n",
      "Loaded padded_block_74.csv, shape: (36, 5)\n",
      "Loaded padded_block_75.csv, shape: (36, 5)\n",
      "Loaded padded_block_76.csv, shape: (36, 5)\n",
      "Loaded padded_block_77.csv, shape: (36, 5)\n",
      "Loaded padded_block_78.csv, shape: (36, 5)\n",
      "Loaded padded_block_79.csv, shape: (36, 5)\n",
      "Loaded padded_block_8.csv, shape: (36, 5)\n",
      "Loaded padded_block_80.csv, shape: (36, 5)\n",
      "Loaded padded_block_81.csv, shape: (36, 5)\n",
      "Loaded padded_block_82.csv, shape: (36, 5)\n",
      "Loaded padded_block_83.csv, shape: (36, 5)\n",
      "Loaded padded_block_84.csv, shape: (36, 5)\n",
      "Loaded padded_block_85.csv, shape: (36, 5)\n",
      "Loaded padded_block_86.csv, shape: (36, 5)\n",
      "Loaded padded_block_87.csv, shape: (36, 5)\n",
      "Loaded padded_block_88.csv, shape: (36, 5)\n",
      "Loaded padded_block_89.csv, shape: (36, 5)\n",
      "Loaded padded_block_9.csv, shape: (36, 5)\n",
      "Loaded padded_block_90.csv, shape: (36, 5)\n",
      "Loaded padded_block_91.csv, shape: (36, 5)\n",
      "Loaded padded_block_92.csv, shape: (36, 5)\n",
      "Loaded padded_block_93.csv, shape: (36, 5)\n",
      "Loaded padded_block_94.csv, shape: (36, 5)\n",
      "Loaded padded_block_95.csv, shape: (36, 5)\n",
      "Loaded padded_block_96.csv, shape: (36, 5)\n",
      "Loaded padded_block_97.csv, shape: (36, 5)\n",
      "Loaded padded_block_98.csv, shape: (36, 5)\n",
      "Loaded padded_block_99.csv, shape: (36, 5)\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        NaN               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0  -256950.0               1            11\n",
      "1        12       5.0  -256950.0               1            11\n",
      "2         4       7.0 -1168050.0               1            11\n",
      "3         5      14.0 -1168050.0               1            11\n",
      "4         1      24.0 -1168050.0               1            11\n",
      "DataFrame size: (36, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the directory containing the data blocks\n",
    "data_directory = \"../data/filtered_blocks_padded/\"\n",
    "\n",
    "# Initialize an empty list to hold all DataFrames\n",
    "data_frames = []\n",
    "\n",
    "for file_name in os.listdir(data_directory):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {file_name}, shape: {df.shape}\")\n",
    "\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one DataFrame\n",
    "combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Check the first few rows of the combined data\n",
    "print(combined_data.head())\n",
    "\n",
    "# Ensure the DataFrame is loaded properly\n",
    "print(df.head())\n",
    "print(f\"DataFrame size: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8b404619-8512-4026-b707-7e0c35f5a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Dataset size: 1\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Dataset size: 1\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the preprocessing function\n",
    "def preprocess_data(df, sequence_length, step_size=1):\n",
    "    inputs = df['sourceID'].values\n",
    "    targets = df['sourceID'].shift(-1).fillna(0).values  # Shift by 1 and replace NaN with 0\n",
    "\n",
    "    # Convert to integer type for model input\n",
    "    inputs = inputs.astype(int)\n",
    "    targets = targets.astype(int)\n",
    "\n",
    "    input_sequences = []\n",
    "    target_sequences = []\n",
    "\n",
    "    # Slide over the entire dataset with overlapping windows\n",
    "    for i in range(0, len(inputs) - sequence_length + 1, step_size):  # Added step_size for overlap\n",
    "        input_sequences.append(inputs[i:i + sequence_length])\n",
    "        target_sequences.append(targets[i:i + sequence_length])\n",
    "\n",
    "    inputs = np.array(input_sequences)\n",
    "    targets = np.array(target_sequences)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "sequence_length = 36  # Example sequence length\n",
    "inputs, targets = preprocess_data(df, sequence_length)\n",
    "print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "# Create a dataset from the inputs and targets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "\n",
    "# Create a dataset with a proper batch size\n",
    "dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "\n",
    "# Print the dataset size to ensure it's not empty\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Check inputs and targets before reshaping\n",
    "inputs, targets = preprocess_data(df, sequence_length)\n",
    "print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "if inputs.size > 0 and targets.size > 0:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "else:\n",
    "    print(\"No sequences generated. Dataset size is 0.\")\n",
    "\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch_inputs, batch_targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(batch_inputs, batch_targets, training=True, look_ahead_mask=None, padding_mask=None)\n",
    "        loss = loss_function(batch_targets, predictions)  # Ensure loss_function is defined\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    return loss  # Make sure this returns the loss\n",
    "    print(f\"Loss: {loss.numpy()}\")\n",
    "    print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "263c2ab9-1b06-4c3f-b5f8-6e614f0431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2a524ca-bbc6-474e-a903-4e8c6c191dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:731: UserWarning: Gradients do not exist for variables ['embeddings', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7621448040008545\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 2, Loss: 0.9441693425178528\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 3, Loss: 0.8866862654685974\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 4, Loss: 0.8138106465339661\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 5, Loss: 0.7934479117393494\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 6, Loss: 0.7764068245887756\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 7, Loss: 0.7428820133209229\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 8, Loss: 0.742789626121521\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 9, Loss: 0.7376158237457275\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 10, Loss: 0.7443320751190186\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 11, Loss: 0.6809525489807129\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 12, Loss: 0.7604783177375793\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 13, Loss: 0.7235222458839417\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 14, Loss: 0.6891064047813416\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 15, Loss: 0.740749716758728\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 16, Loss: 0.7050431966781616\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 17, Loss: 0.6849164962768555\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 18, Loss: 0.6571060419082642\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 19, Loss: 0.6879213452339172\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 20, Loss: 0.6718630194664001\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 21, Loss: 0.7316665649414062\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 22, Loss: 0.7017659544944763\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 23, Loss: 0.6975657939910889\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 24, Loss: 0.697327733039856\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 25, Loss: 0.6734949946403503\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 26, Loss: 0.6766108274459839\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 27, Loss: 0.6934020519256592\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 28, Loss: 0.7034159302711487\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 29, Loss: 0.6666679978370667\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 30, Loss: 0.6615449786186218\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 31, Loss: 0.7115243077278137\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 32, Loss: 0.7102487087249756\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 33, Loss: 0.6663181185722351\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 34, Loss: 0.7164242267608643\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 35, Loss: 0.6967278122901917\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 36, Loss: 0.7015846371650696\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 37, Loss: 0.7061105370521545\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 38, Loss: 0.706130862236023\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 39, Loss: 0.6839973330497742\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 40, Loss: 0.7026584148406982\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 41, Loss: 0.6964061260223389\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 42, Loss: 0.6507062315940857\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 43, Loss: 0.7044567465782166\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 44, Loss: 0.6979115009307861\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 45, Loss: 0.6747217774391174\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 46, Loss: 0.6662842035293579\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 47, Loss: 0.7043020725250244\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 48, Loss: 0.6908301115036011\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 49, Loss: 0.6683880686759949\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 50, Loss: 0.6165156364440918\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 51, Loss: 0.6205955147743225\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 52, Loss: 0.5614656209945679\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 53, Loss: 0.5552294254302979\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 54, Loss: 0.4953775405883789\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 55, Loss: 0.4074300527572632\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 56, Loss: 0.6587591767311096\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 57, Loss: 0.4132745563983917\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 58, Loss: 0.8542182445526123\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 59, Loss: 0.4152790307998657\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 60, Loss: 0.590986430644989\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 61, Loss: 0.5121517777442932\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 62, Loss: 0.41979357600212097\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 63, Loss: 0.4128671884536743\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 64, Loss: 0.39078786969184875\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 65, Loss: 0.5824684500694275\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 66, Loss: 0.4108733534812927\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 67, Loss: 0.39085185527801514\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 68, Loss: 0.3757886290550232\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 69, Loss: 0.3924116790294647\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 70, Loss: 0.38246485590934753\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 71, Loss: 0.3595191538333893\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 72, Loss: 0.38945063948631287\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 73, Loss: 0.39936330914497375\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 74, Loss: 0.40103238821029663\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 75, Loss: 0.40351736545562744\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 76, Loss: 0.4156533479690552\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 77, Loss: 0.4011739194393158\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 78, Loss: 0.38238006830215454\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 79, Loss: 0.39793655276298523\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 80, Loss: 0.3917500376701355\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 81, Loss: 0.39043986797332764\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 82, Loss: 0.3800238370895386\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 83, Loss: 0.38575848937034607\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 84, Loss: 0.3768864870071411\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 85, Loss: 0.3999461233615875\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 86, Loss: 0.36841681599617004\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 87, Loss: 0.3959876298904419\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 88, Loss: 0.4100132882595062\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 89, Loss: 0.366735577583313\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 90, Loss: 0.3919883966445923\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 91, Loss: 0.37513259053230286\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 92, Loss: 0.385583758354187\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 93, Loss: 0.380694180727005\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 94, Loss: 0.3800453245639801\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 95, Loss: 0.35307571291923523\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 96, Loss: 0.3760117292404175\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 97, Loss: 0.3859366178512573\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 98, Loss: 0.3785824477672577\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 99, Loss: 0.3878483474254608\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 100, Loss: 0.36845070123672485\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_inputs, batch_targets in dataset:\n",
    "        print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")\n",
    "        \n",
    "        # Ensure the shapes are correct for your model\n",
    "        batch_inputs = tf.reshape(batch_inputs, [batch_size, -1])\n",
    "        batch_targets = tf.reshape(batch_targets, [batch_size, -1])\n",
    "\n",
    "        # Get the loss from the train_step function\n",
    "        loss = train_step(batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    # Only print loss if dataset is not empty\n",
    "    if len(dataset) > 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataset)}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch + 1}, No batches to train on.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b35bc5ae-e467-40ae-8b02-839ab8445d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sequence 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Final predicted sequence (no padding): [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Raw predictions: [[[11.141112    0.7925508  -2.2449324  -1.9368104  -0.66093343\n",
      "   -0.42378095 -0.32271868  1.0319393   0.34296688 -0.34836242\n",
      "    0.60909474 -4.1248612   0.3573203 ]\n",
      "  [11.141213    0.7959757  -2.2479897  -1.9368912  -0.66069156\n",
      "   -0.42973408 -0.3171384   1.0291585   0.3443183  -0.34689116\n",
      "    0.6109291  -4.127986    0.35510483]\n",
      "  [11.139138    0.79992646 -2.2505004  -1.9388428  -0.6607887\n",
      "   -0.43323648 -0.31596297  1.0266678   0.34638086 -0.34579125\n",
      "    0.6135734  -4.1344137   0.35545665]\n",
      "  [11.136744    0.80324954 -2.2512136  -1.9425532  -0.659811\n",
      "   -0.43253082 -0.3188786   1.0250657   0.348593   -0.3459526\n",
      "    0.6155815  -4.139879    0.35716778]\n",
      "  [11.137002    0.80491996 -2.2501664  -1.9466611  -0.6588898\n",
      "   -0.42769122 -0.32169104  1.0252526   0.3484024  -0.34739724\n",
      "    0.61835283 -4.1394815   0.35664257]\n",
      "  [11.139052    0.8038143  -2.2480295  -1.9498744  -0.65948105\n",
      "   -0.4206547  -0.32142812  1.026939    0.3452667  -0.34665874\n",
      "    0.6207717  -4.13462     0.35334814]\n",
      "  [11.141514    0.80127263 -2.2463188  -1.9523345  -0.66206926\n",
      "   -0.4142958  -0.3190188   1.0300891   0.34136894 -0.34204555\n",
      "    0.621707   -4.127885    0.34987175]\n",
      "  [11.142504    0.7970432  -2.244986   -1.9551584  -0.6651561\n",
      "   -0.4105472  -0.31808028  1.0335544   0.33884668 -0.33539358\n",
      "    0.6206794  -4.122764    0.35016793]\n",
      "  [11.140761    0.793389   -2.2445555  -1.9561454  -0.6672281\n",
      "   -0.4111144  -0.31989965  1.0357338   0.33784035 -0.3302294\n",
      "    0.61643    -4.122415    0.35496253]\n",
      "  [11.137123    0.7921836  -2.2434518  -1.9534875  -0.66765237\n",
      "   -0.41514286 -0.3227569   1.0365003   0.33919272 -0.32937312\n",
      "    0.6097088  -4.1264863   0.36296263]\n",
      "  [11.134728    0.79383415 -2.2417214  -1.9503198  -0.6662272\n",
      "   -0.41891727 -0.3247222   1.0345333   0.3403346  -0.33401743\n",
      "    0.6047426  -4.129688    0.36831078]\n",
      "  [11.134553    0.7958649  -2.241626   -1.9487365  -0.6638508\n",
      "   -0.42099595 -0.32440537  1.0313977   0.3381672  -0.33963603\n",
      "    0.6035818  -4.1289835   0.36826688]\n",
      "  [11.136195    0.7965523  -2.2428749  -1.9493449  -0.6623648\n",
      "   -0.42172447 -0.32066146  1.0293036   0.33327898 -0.3419501\n",
      "    0.6053915  -4.1252756   0.36458302]\n",
      "  [11.138435    0.79639184 -2.2439053  -1.9508226  -0.6625885\n",
      "   -0.42072347 -0.31557113  1.0284588   0.3290441  -0.34053454\n",
      "    0.6074578  -4.1203156   0.36051312]\n",
      "  [11.139907    0.79652447 -2.245791   -1.9522185  -0.66369766\n",
      "   -0.41844714 -0.3139025   1.0293669   0.3274844  -0.33691397\n",
      "    0.608282   -4.1178455   0.359151  ]\n",
      "  [11.140345    0.7984279  -2.2476072  -1.9523052  -0.66571194\n",
      "   -0.41585368 -0.3175722   1.0321769   0.32941917 -0.3342305\n",
      "    0.60842425 -4.118528    0.36176494]\n",
      "  [11.139965    0.80096924 -2.2481582  -1.9508337  -0.66721225\n",
      "   -0.4155936  -0.32509014  1.0354578   0.3334089  -0.33423963\n",
      "    0.60861844 -4.1214232   0.3666722 ]\n",
      "  [11.140103    0.80317163 -2.2467365  -1.9476881  -0.66787064\n",
      "   -0.41714358 -0.33150318  1.0371573   0.33690903 -0.33762968\n",
      "    0.6092478  -4.125115    0.3689181 ]\n",
      "  [11.140526    0.80339223 -2.2449846  -1.9443831  -0.6685025\n",
      "   -0.42040697 -0.33248392  1.0373361   0.33693525 -0.3412895\n",
      "    0.61086756 -4.127279    0.36628383]\n",
      "  [11.141215    0.80120575 -2.2448497  -1.9429141  -0.66842985\n",
      "   -0.42362887 -0.3287419   1.0365881   0.3345867  -0.34296614\n",
      "    0.6135225  -4.1282473   0.36070874]\n",
      "  [11.141304    0.79842013 -2.2452445  -1.9429718  -0.66806513\n",
      "   -0.42452273 -0.32438025  1.0354025   0.33250204 -0.34326208\n",
      "    0.61514175 -4.128751    0.3564864 ]\n",
      "  [11.140775    0.7963583  -2.2459002  -1.9434881  -0.6671321\n",
      "   -0.42319262 -0.32185832  1.0355047   0.33383268 -0.34318897\n",
      "    0.6140464  -4.129178    0.35509098]\n",
      "  [11.1400175   0.79550517 -2.246447   -1.944235   -0.6653469\n",
      "   -0.42119917 -0.3227053   1.0368838   0.33785346 -0.3436881\n",
      "    0.6123747  -4.1304383   0.35718584]\n",
      "  [11.141061    0.79765624 -2.2462082  -1.9447454  -0.66338354\n",
      "   -0.41934714 -0.324888    1.0388279   0.3414779  -0.3443535\n",
      "    0.61186886 -4.131277    0.36116058]\n",
      "  [11.142958    0.8006779  -2.245437   -1.945338   -0.66172785\n",
      "   -0.41973463 -0.32647204  1.0399531   0.3427763  -0.34500152\n",
      "    0.6133734  -4.1320195   0.36331162]\n",
      "  [11.144689    0.80228764 -2.2449942  -1.9451522  -0.66147083\n",
      "   -0.4228055  -0.32487267  1.0403866   0.3411272  -0.34425378\n",
      "    0.61612505 -4.1336102   0.36244643]\n",
      "  [11.144695    0.80229133 -2.2452111  -1.9441864  -0.6621838\n",
      "   -0.42616412 -0.3219278   1.0384015   0.33815396 -0.34259936\n",
      "    0.6183549  -4.136217    0.36016217]\n",
      "  [11.143193    0.8022654  -2.2462664  -1.942887   -0.6626428\n",
      "   -0.42844257 -0.31992415  1.0348513   0.3360816  -0.34215805\n",
      "    0.6192572  -4.139104    0.3588579 ]\n",
      "  [11.141356    0.8038108  -2.2489667  -1.9421984  -0.66204566\n",
      "   -0.42915118 -0.31910375  1.0317644   0.33694893 -0.343977\n",
      "    0.6196044  -4.141649    0.359917  ]\n",
      "  [11.140826    0.80671954 -2.2521193  -1.9420434  -0.66084987\n",
      "   -0.42941943 -0.31797317  1.0302639   0.3389922  -0.34706014\n",
      "    0.62046456 -4.142278    0.36141613]\n",
      "  [11.141029    0.8090504  -2.2538867  -1.942339   -0.6600266\n",
      "   -0.43109316 -0.3169204   1.0298021   0.34005016 -0.34925693\n",
      "    0.62259984 -4.141403    0.36349797]\n",
      "  [11.141235    0.8088336  -2.2538915  -1.9438268  -0.66012317\n",
      "   -0.43474218 -0.31579664  1.0299327   0.3420975  -0.34761336\n",
      "    0.62596345 -4.1414967   0.36451662]\n",
      "  [11.14014     0.80576503 -2.2523417  -1.9465581  -0.6622255\n",
      "   -0.43849492 -0.31526968  1.0310502   0.3426413  -0.34257135\n",
      "    0.62676847 -4.141564    0.36451426]\n",
      "  [11.138105    0.8011015  -2.250695   -1.9476233  -0.66483843\n",
      "   -0.4405068  -0.31578228  1.032165    0.34028435 -0.33763418\n",
      "    0.62352276 -4.1412697   0.36373556]\n",
      "  [11.136263    0.79662293 -2.2483158  -1.9468617  -0.6665564\n",
      "   -0.43983132 -0.3181855   1.0332177   0.33614695 -0.3367404\n",
      "    0.6179842  -4.1388407   0.36281297]\n",
      "  [11.136302    0.7946155  -2.246998   -1.9449909  -0.6661281\n",
      "   -0.43554565 -0.3211171   1.0343556   0.33376297 -0.34021905\n",
      "    0.61337835 -4.135494    0.36253053]]]\n"
     ]
    }
   ],
   "source": [
    "# Sample input, ensure it matches the expected shape (batch_size, sequence_length)\n",
    "sample_inputs = np.array([[10, 4, 5, 1, 12, 8, 9]])  \n",
    "sample_inputs = tf.convert_to_tensor(sample_inputs)\n",
    "\n",
    "# Pad the inputs to match the expected input length of 36\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(sample_inputs, maxlen=36, padding='post')\n",
    "\n",
    "# Reshape padded inputs for batch size of 1\n",
    "padded_inputs = tf.expand_dims(padded_inputs, axis=0)  # Now shape (1, 36)\n",
    "\n",
    "# Make predictions\n",
    "predictions = transformer(padded_inputs, targets=tf.zeros((1, 36)), training=False, look_ahead_mask=None, padding_mask=None)\n",
    "\n",
    "# Convert predictions from logits to class indices\n",
    "predicted_indices = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Print the predicted sequences\n",
    "for i, seq in enumerate(predicted_indices):\n",
    "    print(f\"Predicted sequence {i + 1}: {seq}\")\n",
    "\n",
    "# Remove padding (optional)\n",
    "predicted_sequence = np.where(seq == 0, -1, seq)  # Replace 0 (PADDED) with -1 or another value\n",
    "print(f\"Final predicted sequence (no padding): {predicted_sequence}\")\n",
    "print(\"Raw predictions:\", predictions.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a463857-6a4a-413b-948b-56019d2696af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                  │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">794,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                  │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">794,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_244 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_4 (\u001b[38;5;33mEncoder\u001b[0m)                  │ ?                           │         \u001b[38;5;34m794,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_4 (\u001b[38;5;33mDecoder\u001b[0m)                  │ ?                           │         \u001b[38;5;34m794,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_244 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m13\u001b[0m)                │           \u001b[38;5;34m1,677\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,591,181</span> (6.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,591,181\u001b[0m (6.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,591,181</span> (6.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,591,181\u001b[0m (6.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc0f76-c612-449d-b720-0fb7788c21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
