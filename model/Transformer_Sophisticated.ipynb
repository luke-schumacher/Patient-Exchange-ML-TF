{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4b1f1f0b-04c3-4453-8bd0-61a904b48a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ca8a9abf-a16d-4db2-8f2f-0ee6f95b72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11', 2: 'MRI_EXU_95', 3: 'MRI_FRR_18', 4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264', 6: 'MRI_FRR_3', 7: 'MRI_FRR_34', 8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100', 10: 'MRI_MSR_104', 11: 'MRI_MSR_21', 12: 'MRI_MSR_34',\n",
    "    0: 'PADDED',  # Add a padding category\n",
    "    10: 'START',  # Start token\n",
    "    9: 'END'      # End token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "56f24bff-9b20-4665-8ea2-73708759b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model) // 2)) / np.float32(d_model))\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bc2420f7-ac3b-4e96-99be-0596d1b12e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MultiHeadAttention Layer\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        attention = tf.reshape(attention, (batch_size, -1, self.d_model))\n",
    "        return self.dense(attention)\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3f1db13d-591f-4c18-9578-9d7e2178ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positionwise Feedforward Layer\n",
    "class PositionwiseFeedforward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dense1 = Dense(dff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Define Transformer Block\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output = self.att(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "# Define Encoder Layer\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        return x\n",
    "\n",
    "# Define Decoder Layer\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "757a4aff-c1ce-426b-ae8e-5da424d01a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # Ensure training, mask passed as keywords\n",
    "        attn_output = self.att(x, x, x, mask)  # x already contains embeddings\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "74c56e84-e57b-4f4e-ad09-919e21c802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # training and mask as keyword arguments\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b7faca35-5da9-450b-93c7-bd61ef368962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training=None, look_ahead_mask=None, padding_mask=None):  # Ensure keyword args\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, training=training, mask=look_ahead_mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8503c952-f418-4b96-9256-de552f34558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, targets, training=None, look_ahead_mask=None, padding_mask=None):\n",
    "        enc_output = self.encoder(inputs, training=training, mask=padding_mask)\n",
    "        dec_output = self.decoder(targets, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f80f098f-5cf7-4270-8635-c1d284e0d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(directory, encoding_legend):\n",
    "    all_blocks = []\n",
    "    all_source_ids = np.array(list(encoding_legend.keys())).reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(all_source_ids)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            block = pd.read_csv(file_path)\n",
    "\n",
    "            assert block.shape == (36, 5), f\"Block {filename} has an unexpected shape {block.shape}\"\n",
    "\n",
    "            source_ids = block[['sourceID']].values.reshape(-1, 1)\n",
    "            one_hot_encoded_sourceID = encoder.transform(source_ids)\n",
    "\n",
    "            # Normalize additional features\n",
    "            timediff = block[['timediff']].values\n",
    "            ptab = np.nan_to_num(block[['PTAB']].values)\n",
    "            timediff = (timediff - np.mean(timediff)) / np.std(timediff)\n",
    "            ptab = (ptab - np.mean(ptab)) / np.std(ptab)\n",
    "            body_group_from = block[['BodyGroup_from']].values\n",
    "            body_group_to = block[['BodyGroup_to']].values\n",
    "\n",
    "            # Create input block with start and end tokens\n",
    "            X_block = np.concatenate((one_hot_encoded_sourceID, timediff, ptab, body_group_from, body_group_to), axis=1)\n",
    "            all_blocks.append(X_block)\n",
    "\n",
    "    all_blocks = np.stack(all_blocks, axis=0)\n",
    "    return all_blocks, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "da9a3972-344e-4087-ad19-9dbd56b5d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the 150 CSV data blocks\n",
    "data_directory = \"../data/filtered_blocks_padded/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7300fa33-e507-4ce2-a127-c650363c78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data and obtain one-hot encoding for sourceIDs\n",
    "all_blocks, encoder = preprocess_data(data_directory, encoding_legend)\n",
    "\n",
    "# Parameters for model\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "input_vocab_size = len(encoder.categories_[0])  # Number of unique sourceIDs\n",
    "target_vocab_size = input_vocab_size  # Assuming prediction is similar to input\n",
    "pe_input = 1000\n",
    "pe_target = 1000\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3b6ae9a0-fb85-4416-bbef-808d5a83cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer model\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "07c0efc5-d222-482f-8d7c-789ae6f4ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input (creating dummy data for testing)\n",
    "# Adjust batch size based on your data length\n",
    "batch_size = min(32, len(df) // 2)  # Ensure at least some data for batching\n",
    "max_seq_length = 34  # Adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e0137e00-3b39-4bf2-99ea-59c4544b48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy input and target sequences (for illustration)\n",
    "inputs = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=input_vocab_size)\n",
    "targets = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=target_vocab_size)\n",
    "look_ahead_mask = None\n",
    "padding_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "bf55e234-7c56-4ee3-bbb4-0a5b083c9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 34, 13)\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "output = transformer(inputs=inputs, targets=targets, training=True, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "print(output.shape)  # Should now work correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c6bc859b-feba-4929-80d5-28bc8033eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))  # Mask out padding tokens\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f7c812bd-387f-4556-a213-4090cc41fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0     -500.0               1             4\n",
      "1         4       8.0 -1128900.0               1             4\n",
      "2         5      16.0 -1128900.0               1             4\n",
      "3         1      29.0 -1128900.0               1             4\n",
      "4        12      35.0 -1128900.0               1             4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data block into a DataFrame\n",
    "data_block = \"\"\"\n",
    "sourceID,timediff,PTAB,BodyGroup_from,BodyGroup_to\n",
    "10,0.0,-500.0,1,4\n",
    "4,8.0,-1128900.0,1,4\n",
    "5,16.0,-1128900.0,1,4\n",
    "1,29.0,-1128900.0,1,4\n",
    "12,35.0,-1128900.0,1,4\n",
    "8,36.0,-1128900.0,1,4\n",
    "1,55.0,-1128900.0,1,4\n",
    "4,57.0,-200.0,1,4\n",
    "5,64.0,-200.0,1,4\n",
    "9,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "0,89.0,-200.0,1,4\n",
    "\"\"\"\n",
    "\n",
    "# Convert the string to a pandas DataFrame\n",
    "from io import StringIO\n",
    "df = pd.read_csv(StringIO(data_block))\n",
    "\n",
    "# Check the first few rows to ensure it's loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "8b404619-8512-4026-b707-7e0c35f5a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the preprocessing function\n",
    "def preprocess_data(df):\n",
    "    inputs = df['sourceID'].values\n",
    "    targets = df['sourceID'].shift(-1).fillna(0).values  # Shift by 1 and replace NaN with 0\n",
    "    \n",
    "    # Convert to integer type for model input\n",
    "    inputs = inputs.astype(int)\n",
    "    targets = targets.astype(int)\n",
    "\n",
    "    # Reshape inputs and targets into sequences (batch_size, sequence_length)\n",
    "    inputs = np.reshape(inputs, (-1, 1))  # Reshape for each input to be a sequence\n",
    "    targets = np.reshape(targets, (-1, 1))  # Reshape for each target to be a sequence\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "# After modifying, apply the preprocessing\n",
    "inputs, targets = preprocess_data(df)\n",
    "\n",
    "# Create a dataset from the inputs and targets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "\n",
    "# Create a dataset with a proper batch size\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# Print the dataset size to ensure it's not empty\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch_inputs, batch_targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(batch_inputs, batch_targets, training=True, look_ahead_mask=None, padding_mask=None)\n",
    "        loss = loss_function(batch_targets, predictions)  # Ensure loss_function is defined\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    return loss  # Make sure this returns the loss\n",
    "    print(f\"Loss: {loss.numpy()}\")\n",
    "    print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "263c2ab9-1b06-4c3f-b5f8-6e614f0431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e2a524ca-bbc6-474e-a903-4e8c6c191dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:731: UserWarning: Gradients do not exist for variables ['embeddings', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 1, Loss: 1.1127723455429077\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 2, Loss: 0.9065909385681152\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 3, Loss: 0.8176503777503967\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 4, Loss: 0.49855658411979675\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 5, Loss: 0.5470494627952576\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 6, Loss: 0.47231337428092957\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 7, Loss: 0.4809064269065857\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 8, Loss: 0.4690232276916504\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 9, Loss: 0.4362650513648987\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Inputs shape: (17, 1), Targets shape: (17, 1)\n",
      "Epoch 10, Loss: 0.427875280380249\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_inputs, batch_targets in dataset:\n",
    "        print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")\n",
    "        \n",
    "        # Ensure the shapes are correct for your model\n",
    "        batch_inputs = tf.reshape(batch_inputs, [batch_size, -1])\n",
    "        batch_targets = tf.reshape(batch_targets, [batch_size, -1])\n",
    "\n",
    "        # Get the loss from the train_step function\n",
    "        loss = train_step(batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    # Only print loss if dataset is not empty\n",
    "    if len(dataset) > 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataset)}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch + 1}, No batches to train on.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b35bc5ae-e467-40ae-8b02-839ab8445d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sequence 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Assume we have some input data for prediction\n",
    "# For example, you can use a small batch of data from your dataset\n",
    "sample_inputs = np.array([[10, 4, 5, 1, 12, 8]])  # Sample input\n",
    "sample_inputs = tf.convert_to_tensor(sample_inputs)\n",
    "\n",
    "# Add padding if your model expects sequences of a fixed length\n",
    "# For example, if the model expects a maximum sequence length of 34, pad as necessary\n",
    "# Here, let's pad to length 34 with zeros (or adjust accordingly)\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(sample_inputs, maxlen=34, padding='post')\n",
    "\n",
    "# Make predictions\n",
    "predictions = transformer(padded_inputs, targets=tf.zeros((1, 34)), training=False, look_ahead_mask=None, padding_mask=None)\n",
    "\n",
    "# Convert predictions from logits to class indices\n",
    "predicted_indices = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Print the predicted sequences\n",
    "for i, seq in enumerate(predicted_indices):\n",
    "    print(f\"Predicted sequence {i+1}: {seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a463857-6a4a-413b-948b-56019d2696af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc0f76-c612-449d-b720-0fb7788c21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
