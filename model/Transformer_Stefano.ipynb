{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e91a6689-efe7-41ba-9ee2-afa668d26754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Output library versions\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb1b001d-c4b2-4ec0-af1c-e060788fe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated encoding legend\n",
    "ENCODING_LEGEND = {\n",
    "    'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_3': 6, 'MRI_FRR_34': 7, 'MRI_MPT_1005': 8,\n",
    "    'MRI_MSR_100': 9, 'MRI_MSR_104': 10, 'MRI_MSR_21': 11, 'MRI_MSR_34': 12,\n",
    "    'START': 13,  # Start token\n",
    "    'END': 14     # End token\n",
    "}\n",
    "\n",
    "CHAR_TO_INT = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    '10': 10,\n",
    "    '11': 11,\n",
    "    '12': 12,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f36d62a4-3ba4-47cf-a556-24b4829ab219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- DATA FUNCTIONS -----------------------------------\n",
    "\n",
    "# Updated start and end tokens\n",
    "START_TOKEN = 13\n",
    "END_TOKEN = 14\n",
    "\n",
    "def generate_data(data_size=100):\n",
    "    \"\"\"\n",
    "    Generate synthetic sourceID data sequences.\n",
    "    Each sequence starts with the START token (13) and ends with the END token (14).\n",
    "    Random sourceIDs (from 1 to 12) are included in between.\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_cond_sequence(condition):\n",
    "        \"\"\"\n",
    "        Generate a sequence of sourceIDs based on a condition.\n",
    "        The condition is an integer (sourceID) between 1 and 12.\n",
    "        \"\"\"\n",
    "        if condition < 1 or condition > 12:\n",
    "            raise ValueError(\"Condition must be between 1 and 12.\")\n",
    "\n",
    "        random_number = np.random.choice([0, 1, 2])\n",
    "\n",
    "        if random_number == 0:\n",
    "            length = 3\n",
    "        elif random_number == 1:\n",
    "            length = 6\n",
    "        elif random_number == 2:\n",
    "            length = 10\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # Generate random sourceIDs for the sequence\n",
    "        return np.random.randint(1, 13, size=length).tolist()\n",
    "\n",
    "    \n",
    "    sequences_lists = []\n",
    "\n",
    "    for i in range(data_size):\n",
    "        # Randomly select a condition (sourceID between 1 and 12)\n",
    "        condition = np.random.randint(1, 12)\n",
    "\n",
    "        # Generate a sequence based on the condition\n",
    "        seq = generate_cond_sequence(condition)\n",
    "\n",
    "        # Add start and end tokens to the sequence\n",
    "        seq = [START_TOKEN] + seq + [END_TOKEN]\n",
    "\n",
    "        \n",
    "        sequences_lists.append(seq)\n",
    "\n",
    "    return sequences_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2600d879-cca7-4d62-8ea6-ffc729fa0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end_tokens(seqs):\n",
    "    new_seqs = [[START_TOKEN] + seq + [END_TOKEN] for seq in seqs]\n",
    "    return new_seqs\n",
    "\n",
    "    \n",
    "    \n",
    "def make_same_length(seqs):\n",
    "    max_length = max(len(seq) for seq in seqs)\n",
    "    new_seqs = [seq + [END_TOKEN] * (max_length - len(seq)) for seq in seqs]\n",
    "    return new_seqs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_training_data(seqs):\n",
    "    input_seqs = [seq[:-1] for seq in seqs]\n",
    "    output_seqs = [seq[1:] for seq in seqs]\n",
    "    return input_seqs, output_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "464e3a43-9fba-48b7-b886-90eb9d2291bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "RAW_STRINGS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "CHAR_TO_INT = {str(i): i for i in range(11)}  # Includes 0 to 10\n",
    "INT_TO_CHAR = {v: k for k, v in CHAR_TO_INT.items()}\n",
    "\n",
    "class ConditionMapper:\n",
    "    def __init__(self):\n",
    "        # Define your mappings as before\n",
    "        self.integer_map = ENCODING_LEGEND.copy()  # Your original map\n",
    "        self.string_map = {v: k for k, v in self.integer_map.items()}  # Reverse mapping for integer to string\n",
    "        self.dimension = len(self.integer_map) + 1  # Account for possible 'END' token\n",
    "\n",
    "    def map_to_ints(self, input_string):\n",
    "        # Check if the input is a string (e.g., 'MRI_MSR_100') or an integer (e.g., 10)\n",
    "        if isinstance(input_string, int):\n",
    "            # Check if the integer exists in the reverse mapping (for keys like 10 corresponding to 'MRI_MSR_100')\n",
    "            input_string = self.string_map.get(input_string, None)\n",
    "            if input_string is None:\n",
    "                raise KeyError(f\"Integer '{input_string}' not found in string map\")\n",
    "        \n",
    "        # Now input_string should be a valid string that can be mapped to an integer\n",
    "        if input_string not in self.integer_map:\n",
    "            raise KeyError(f\"Character '{input_string}' not found in integer map\")\n",
    "        \n",
    "        return np.array([self.integer_map[input_string]])\n",
    "\n",
    "    def map_list_to_ints_vectors(self, list_of_strings):\n",
    "        return np.array([self.map_to_ints(input_string) for input_string in list_of_strings])\n",
    "\n",
    "    def map_ints_to_string(self, input_ints):\n",
    "        return \"\".join([self.string_map.get(integer, '') for integer in input_ints])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "274cf379-1295-4e82-81d5-bdafdb70b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqMapper:\n",
    "    def __init__(self):\n",
    "        self.integer_map = ENCODING_LEGEND.copy()\n",
    "        n_ints = len(self.integer_map)\n",
    "        \n",
    "        # Add START and END tokens\n",
    "        self.integer_map['START'] = START_TOKEN\n",
    "        self.integer_map['END'] = END_TOKEN\n",
    "        \n",
    "        #Update dimension (max index + 1 for vocabulary size)\n",
    "        self.dimension = max(self.integer_map.values()) + 1\n",
    "\n",
    "        # Reverse mapping\n",
    "        self.string_map = {v: k for k, v in self.integer_map.items()}\n",
    "\n",
    "    \n",
    "    def map_to_ints(self, input_string):\n",
    "    # Handle integer inputs\n",
    "        if isinstance(input_string, int):\n",
    "            mapped_string = self.string_map.get(input_string)\n",
    "            if mapped_string is None:\n",
    "                raise KeyError(f\"Integer '{input_string}' not found in string map\")\n",
    "            input_string = mapped_string\n",
    "\n",
    "    # Ensure input_string is now a valid string\n",
    "        if input_string not in self.integer_map:\n",
    "            raise KeyError(f\"Character '{input_string}' not found in integer map\")\n",
    "    \n",
    "        return np.array([self.integer_map[input_string]])\n",
    "\n",
    "\n",
    "    \n",
    "    def map_list_to_ints_vectors(self, list_of_strings):\n",
    "        input_length = len(list_of_strings)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        for input_string in list_of_strings:\n",
    "            vectors.append(self.map_to_ints(input_string))\n",
    "            \n",
    "        vectors = np.asarray(vectors)\n",
    "        \n",
    "        return vectors\n",
    "    \n",
    "    def map_ints_to_string(self, input_ints):\n",
    "        string = \"\"\n",
    "        \n",
    "        for integer in input_ints:\n",
    "            string += self.string_map[integer]\n",
    "            \n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf9eaa06-b19f-4e12-807c-2af1f9c35ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_training_data(input_train, output_train, mapper):\n",
    "    seq_mapper = mapper\n",
    "    converted_input_train = seq_mapper.map_list_to_ints_vectors(input_train)\n",
    "    converted_output_train = seq_mapper.map_list_to_ints_vectors(output_train)\n",
    "    return converted_input_train, converted_output_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d26f0f4a-0b95-42f3-89cd-50b4d6fdfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- TENSORFLOW LAYERS AND MODELS -----------------------------------\n",
    "    \n",
    "# --------------------------------------- masked layers\n",
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match) / tf.reduce_sum(mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d18f78f-f364-4b09-a469-eb94a19f93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- positional embedding\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth  # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000 ** depths)  # (1, depth)\n",
    "    angle_rads = positions * angle_rates  # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size,\n",
    "                 d_model,\n",
    "                 use_embedding=True):\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_embedding = use_embedding\n",
    "\n",
    "        if self.use_embedding:\n",
    "            self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        else:\n",
    "            self.embedding = tf.keras.layers.Dense(d_model, activation=\"relu\")\n",
    "\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        if self.use_embedding:\n",
    "            return self.embedding.compute_mask(*args, **kwargs)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensure x is a 2D tensor: (batch_size, seq_len)\n",
    "        x = self.embedding(x)  # Convert token indices to embeddings\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # Scale embeddings\n",
    "        length = tf.shape(x)[1]  # seq_len\n",
    "        x += self.pos_encoding[tf.newaxis, :length, :]  # Add positional encodings\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52c8cda8-ca1f-4773-8a22-7c3a5999c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- attention layers\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask=True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SelfAttentionFeedForwardLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1,\n",
    "                 attention=\"global\"):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if attention == \"global\":\n",
    "            self.self_attention = GlobalSelfAttention(\n",
    "                num_heads=num_heads,\n",
    "                key_dim=d_model,\n",
    "                dropout=dropout_rate)\n",
    "        elif attention == \"causal\":\n",
    "            self.self_attention = CausalSelfAttention(\n",
    "                num_heads=num_heads,\n",
    "                key_dim=d_model,\n",
    "                dropout=dropout_rate)\n",
    "        else:\n",
    "            raise NotImplemented(f\"The choice {attention} for attention is not implemented.\")\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SelfAttentionCrossAttentionFeedForwardLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 dropout_rate=0.1,\n",
    "                 attention=\"causal\"):\n",
    "\n",
    "        super(SelfAttentionCrossAttentionFeedForwardLayer, self).__init__()\n",
    "\n",
    "        if attention == \"global\":\n",
    "            self.self_attention = GlobalSelfAttention(\n",
    "                num_heads=num_heads,\n",
    "                key_dim=d_model,\n",
    "                dropout=dropout_rate)\n",
    "        elif attention == \"causal\":\n",
    "            self.self_attention = CausalSelfAttention(\n",
    "                num_heads=num_heads,\n",
    "                key_dim=d_model,\n",
    "                dropout=dropout_rate)\n",
    "        else:\n",
    "            raise NotImplemented(f\"The choice {attention} for attention is not implemented.\")\n",
    "\n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, context):\n",
    "        x = self.self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "        # Cache the last attention scores for plotting later\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x\n",
    "    \n",
    "# --------------------------------------- encoder\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, *, \n",
    "                 num_layers, \n",
    "                 d_model, \n",
    "                 num_heads,\n",
    "                 dff, \n",
    "                 vocab_size, \n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(\n",
    "            vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            SelfAttentionFeedForwardLayer(d_model=d_model,\n",
    "                                          num_heads=num_heads,\n",
    "                                          dff=dff,\n",
    "                                          dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    \n",
    "# --------------------------------------- decoder\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                                 d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            SelfAttentionCrossAttentionFeedForwardLayer(d_model=d_model, num_heads=num_heads,\n",
    "                                                        dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "        return x # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "068df023-b466-4960-af54-4819cb6cd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, *, \n",
    "                 num_layers, \n",
    "                 d_model, \n",
    "                 num_heads, \n",
    "                 dff,\n",
    "                 input_vocab_size, \n",
    "                 target_vocab_size, \n",
    "                 dropout_rate=0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers=num_layers, \n",
    "                               d_model=d_model,\n",
    "                               num_heads=num_heads, \n",
    "                               dff=dff,\n",
    "                               vocab_size=input_vocab_size,\n",
    "                               dropout_rate=dropout_rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               d_model=d_model,\n",
    "                               num_heads=num_heads, \n",
    "                               dff=dff,\n",
    "                               vocab_size=target_vocab_size,\n",
    "                               dropout_rate=dropout_rate)\n",
    "\n",
    "        self.final_layer = tf.keras.Sequential([tf.keras.layers.Dense(target_vocab_size)])\n",
    "        \n",
    "    def save_model_weights(self, save_folder):\n",
    "        self.encoder.save_weights(os.path.join(save_folder, \"encoder.weights.h5\"))\n",
    "        self.decoder.save_weights(os.path.join(save_folder, \"decoder.weights.h5\"))\n",
    "        self.final_layer.save_weights(os.path.join(save_folder, \"final_layer.weights.h5\"))\n",
    "\n",
    "    def load_model_from_weights(self, save_folder):\n",
    "        self.encoder.load_weights(os.path.join(save_folder, \"encoder.weights.h5\"))\n",
    "        self.decoder.load_weights(os.path.join(save_folder, \"decoder.weights.h5\"))\n",
    "        self.final_layer.load_weights(os.path.join(save_folder, \"final_layer.weights.h5\"))\n",
    "\n",
    "    def get_models(self):\n",
    "        return self.encoder, self.decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ensure inputs are indices, not embeddings\n",
    "        encoder_input = inputs\n",
    "        decoder_input = inputs  # Modify this if you use separate inputs for decoder\n",
    "\n",
    "        # Pass token indices (2D) to encoder\n",
    "        encoder_embeddings = self.encoder(encoder_input)  # Shape `(batch_size, seq_len, d_model)`\n",
    "\n",
    "        # Pass encoder output and token indices to decoder\n",
    "        decoder_embeddings = self.decoder(decoder_input, encoder_embeddings)  # Shape `(batch_size, seq_len, d_model)`\n",
    "\n",
    "        # Final dense layer for predictions\n",
    "        logits = self.final_layer(decoder_embeddings)  # Shape `(batch_size, seq_len, vocab_size)`\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb08698e-a921-4dec-af54-e2b24ff04a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, transformer, mapper, sample=True, min_prob=0.05):\n",
    "        self.seq_mapper = mapper\n",
    "        self.transformer = transformer\n",
    "        self.sample = sample\n",
    "        assert 0 <= min_prob < 1\n",
    "        self.min_prob = min_prob\n",
    "\n",
    "    def __call__(self, cond_seq, max_length=30): ### MODIFY\n",
    "        seq_start = START_TOKEN  # Use the integer directly\n",
    "        seq_end = END_TOKEN      # Use the integer directly\n",
    "\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0, seq_start)\n",
    "\n",
    "        # Encoder input is the input sequence for translation\n",
    "        encoder_input = tf.expand_dims(cond_seq, 0)  # Shape: (1, seq_len)\n",
    "\n",
    "        for i in tf.range(max_length):\n",
    "            # Stack the current output and pass it through the model\n",
    "            output = tf.transpose(output_array.stack())\n",
    "            predictions = self.transformer(encoder_input, training=False)\n",
    "\n",
    "            # Get predictions for the next token\n",
    "            predictions = predictions[0, i:i+1, :]  # Shape `(1, vocab_size)`\n",
    "            predicted_id = tf.argmax(predictions, axis=-1).numpy()[0]  # Get the most probable token\n",
    "\n",
    "            output_array = output_array.write(i + 1, predicted_id)\n",
    "\n",
    "            # Stop if END token is predicted\n",
    "            if predicted_id == seq_end:\n",
    "                break\n",
    "\n",
    "        output = tf.transpose(output_array.stack()).numpy()\n",
    "\n",
    "        # Map integers back to their string equivalents (decode to sourceID)\n",
    "        text = [self.seq_mapper.string_map.get(int(tok), \"UNKNOWN\") for tok in output]\n",
    "\n",
    "        return text, None  # Return text and no attention weights for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d90bf018-5c36-42cc-8c72-e157f5dae1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- main use case\n",
    "def main(train=True, \n",
    "         compute_results=True,\n",
    "         n_conds=-1,\n",
    "         n_samples=3,\n",
    "         epochs=1, \n",
    "         checkpoint_name=\"test_transformer\"):\n",
    "    \n",
    "    # Path to tokenization directory\n",
    "    tokenization_dir = \"../data/Tokenization\"  # Directory containing the 300 CSV files\n",
    "    csv_files = sorted(\n",
    "        [os.path.join(tokenization_dir, file) for file in os.listdir(tokenization_dir) if file.endswith(\".csv\")]\n",
    "    )\n",
    "    \n",
    "    # Extract `sourceID` sequences from the CSV files\n",
    "    sequences = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        data = pd.read_csv(file)\n",
    "        source_ids = data['sourceID'].dropna().astype(int).tolist()\n",
    "        if source_ids:\n",
    "            sequences.append(source_ids)     # Use the entire column as the sequence\n",
    "    \n",
    "    # Save raw data for reference\n",
    "    os.makedirs(checkpoint_name, exist_ok=True)\n",
    "    with open(os.path.join(checkpoint_name, \"raw_data.txt\"), \"w\") as f:\n",
    "        print_dict = {}\n",
    "    \n",
    "    # Add start and end tokens\n",
    "    sequences = add_start_end_tokens(sequences)\n",
    "    sequences = make_same_length(sequences)\n",
    "    \n",
    "    # Save processed data for training\n",
    "    with open(os.path.join(checkpoint_name, \"train_data.txt\"), \"w\") as f:\n",
    "        print_dict = {}\n",
    "        for i, seq in enumerate(sequences):\n",
    "            print_dict[i] = seq\n",
    "                \n",
    "        with redirect_stdout(f):\n",
    "            pprint(print_dict)\n",
    "    \n",
    "    # Instantiate mappers for conditions and sequences\n",
    "    seq_mapper = SeqMapper()\n",
    "\n",
    "    \n",
    "    # generate training data\n",
    "    model_input_data, model_output_data = make_training_data(sequences)\n",
    "    model_input_data = tf.convert_to_tensor(model_input_data, dtype=tf.int32)\n",
    "    model_output_data = tf.convert_to_tensor(model_output_data, dtype=tf.int32)\n",
    "    print(f\"Max value in input data: {np.max(model_input_data.numpy())}\")\n",
    "    print(f\"Min value in input data: {np.min(model_input_data.numpy())}\")\n",
    "    print(f\"Expected vocab_size: {seq_mapper.dimension}\")\n",
    "    print(f\"Shape of model_input_data: {model_input_data.shape}\")\n",
    "\n",
    "    # build transformer\n",
    "    \n",
    "    # tf example\n",
    "    # num_layers = 4\n",
    "    # d_model = 128\n",
    "    # dff = 512\n",
    "    # num_heads = 8\n",
    "    # dropout_rate = 0.1\n",
    "    \n",
    "    transformer = Transformer(\n",
    "        num_layers=3,\n",
    "        d_model=32,\n",
    "        num_heads=8,\n",
    "        dff=128,\n",
    "        input_vocab_size=seq_mapper.dimension,\n",
    "        target_vocab_size=seq_mapper.dimension,\n",
    "        dropout_rate=0.1,\n",
    "    )\n",
    "    \n",
    "    transformer(model_input_data)\n",
    "    transformer.summary()\n",
    "    \n",
    "    if not os.path.exists(checkpoint_name):\n",
    "        os.mkdir(checkpoint_name)\n",
    "    \n",
    "    if os.path.exists(os.path.join(checkpoint_name, \"encoder.weights.h5\")):\n",
    "        transformer.load_model_from_weights(checkpoint_name)\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # compile transformer\n",
    "    transformer.compile(\n",
    "        loss=masked_loss,\n",
    "        optimizer='Adam',\n",
    "        metrics=[masked_accuracy])\n",
    "    \n",
    "    if train:\n",
    "        print(\"---------------------------- Training model ----------------------------\")\n",
    "        \n",
    "        # fit transformer on batches\n",
    "        transformer.fit(model_input_data,\n",
    "                        model_output_data,\n",
    "                        epochs=epochs,\n",
    "                        # validation_data=val_batches\n",
    "                        )\n",
    "        \n",
    "        transformer.save_model_weights(checkpoint_name)\n",
    "    \n",
    "    # build translator\n",
    "    translator = Translator(transformer, mapper=(seq_mapper))\n",
    "    \n",
    "    # translate examples\n",
    "    \n",
    "    if compute_results:\n",
    "        print(\"---------------------------- Using model ----------------------------\")\n",
    "        \n",
    "        translation_results = dict()\n",
    "    \n",
    "        for idx, seq in enumerate(sequences[:n_samples]):\n",
    "            print(f\"Generating output for sequence {idx}\")\n",
    "            model_text, _ = translator(seq)  # Get the decoded output\n",
    "            translation_results[idx] = \" \".join(model_text)  # Save as a readable string\n",
    "\n",
    "    # Save results to a file\n",
    "        with open(os.path.join(checkpoint_name, \"results.txt\"), \"w\") as f:\n",
    "            with redirect_stdout(f):\n",
    "                pprint(translation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e468962-6017-4a1f-9ee3-646f67575dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in input data: 14\n",
      "Min value in input data: 1\n",
      "Expected vocab_size: 15\n",
      "Shape of model_input_data: (326, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'global_self_attention_6' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_6' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'global_self_attention_7' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_7' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'global_self_attention_8' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_16' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_8' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_17' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_15' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_cross_attention_feed_forward_layer_6' (of type SelfAttentionCrossAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_18' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_16' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_cross_attention_feed_forward_layer_7' (of type SelfAttentionCrossAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_8' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'cross_attention_8' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_19' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_17' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_cross_attention_feed_forward_layer_8' (of type SelfAttentionCrossAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_20' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)             │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">126,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)             │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">227,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (326, 39, 15)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_2 (\u001b[38;5;33mEncoder\u001b[0m)             │ ?                      │       \u001b[38;5;34m126,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_5 (\u001b[38;5;33mDecoder\u001b[0m)             │ ?                      │       \u001b[38;5;34m227,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_20 (\u001b[38;5;33mSequential\u001b[0m)      │ (326, 39, 15)          │           \u001b[38;5;34m495\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,639</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m354,639\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,639</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m354,639\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "\n",
      "---------------------------- Training model ----------------------------\n",
      "Epoch 1/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 90ms/step - loss: 0.1217 - masked_accuracy: 0.9724\n",
      "Epoch 2/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0450 - masked_accuracy: 0.9839\n",
      "Epoch 3/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0296 - masked_accuracy: 0.9894\n",
      "Epoch 4/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0182 - masked_accuracy: 0.9953\n",
      "Epoch 5/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0129 - masked_accuracy: 0.9961\n",
      "Epoch 6/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0093 - masked_accuracy: 0.9981 \n",
      "Epoch 7/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0105 - masked_accuracy: 0.9969\n",
      "Epoch 8/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - loss: 0.0132 - masked_accuracy: 0.9951\n",
      "Epoch 9/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0138 - masked_accuracy: 0.9952\n",
      "Epoch 10/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0095 - masked_accuracy: 0.9974\n",
      "Epoch 11/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0078 - masked_accuracy: 0.9976 \n",
      "Epoch 12/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0067 - masked_accuracy: 0.9983 \n",
      "Epoch 13/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0061 - masked_accuracy: 0.9988\n",
      "Epoch 14/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0067 - masked_accuracy: 0.9982\n",
      "Epoch 15/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0125 - masked_accuracy: 0.9956\n",
      "Epoch 16/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0186 - masked_accuracy: 0.9945\n",
      "Epoch 17/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0316 - masked_accuracy: 0.9887\n",
      "Epoch 18/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0317 - masked_accuracy: 0.9889\n",
      "Epoch 19/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0155 - masked_accuracy: 0.9946\n",
      "Epoch 20/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0140 - masked_accuracy: 0.9957\n",
      "Epoch 21/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0260 - masked_accuracy: 0.9908\n",
      "Epoch 22/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0174 - masked_accuracy: 0.9942\n",
      "Epoch 23/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0164 - masked_accuracy: 0.9939\n",
      "Epoch 24/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0131 - masked_accuracy: 0.9953\n",
      "Epoch 25/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0107 - masked_accuracy: 0.9967\n",
      "Epoch 26/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0126 - masked_accuracy: 0.9962\n",
      "Epoch 27/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0129 - masked_accuracy: 0.9958\n",
      "Epoch 28/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0118 - masked_accuracy: 0.9969\n",
      "Epoch 29/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0113 - masked_accuracy: 0.9966\n",
      "Epoch 30/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0102 - masked_accuracy: 0.9967 \n",
      "Epoch 31/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0076 - masked_accuracy: 0.9977\n",
      "Epoch 32/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0058 - masked_accuracy: 0.9987\n",
      "Epoch 33/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0056 - masked_accuracy: 0.9984\n",
      "Epoch 34/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0078 - masked_accuracy: 0.9974\n",
      "Epoch 35/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0062 - masked_accuracy: 0.9983\n",
      "Epoch 36/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0061 - masked_accuracy: 0.9985\n",
      "Epoch 37/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0037 - masked_accuracy: 0.9990\n",
      "Epoch 38/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0028 - masked_accuracy: 0.9993\n",
      "Epoch 39/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0098 - masked_accuracy: 0.9970\n",
      "Epoch 40/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0139 - masked_accuracy: 0.9954\n",
      "Epoch 41/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0397 - masked_accuracy: 0.9890\n",
      "Epoch 42/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0290 - masked_accuracy: 0.9894\n",
      "Epoch 43/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0153 - masked_accuracy: 0.9948\n",
      "Epoch 44/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0130 - masked_accuracy: 0.9956\n",
      "Epoch 45/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0071 - masked_accuracy: 0.9979\n",
      "Epoch 46/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0047 - masked_accuracy: 0.9990\n",
      "Epoch 47/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0045 - masked_accuracy: 0.9985\n",
      "Epoch 48/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0034 - masked_accuracy: 0.9988\n",
      "Epoch 49/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0029 - masked_accuracy: 0.9994\n",
      "Epoch 50/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0023 - masked_accuracy: 0.9995\n",
      "Epoch 51/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0016 - masked_accuracy: 0.9998 \n",
      "Epoch 52/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0029 - masked_accuracy: 0.9989\n",
      "Epoch 53/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0041 - masked_accuracy: 0.9988\n",
      "Epoch 54/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0058 - masked_accuracy: 0.9979\n",
      "Epoch 55/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0213 - masked_accuracy: 0.9935\n",
      "Epoch 56/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0134 - masked_accuracy: 0.9955\n",
      "Epoch 57/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0118 - masked_accuracy: 0.9967 \n",
      "Epoch 58/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0044 - masked_accuracy: 0.9985\n",
      "Epoch 59/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0044 - masked_accuracy: 0.9988\n",
      "Epoch 60/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0024 - masked_accuracy: 0.9996\n",
      "Epoch 61/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0013 - masked_accuracy: 0.9999\n",
      "Epoch 62/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 9.9256e-04 - masked_accuracy: 0.9999\n",
      "Epoch 63/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0011 - masked_accuracy: 0.9999\n",
      "Epoch 64/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0010 - masked_accuracy: 0.9997\n",
      "Epoch 65/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 8.0956e-04 - masked_accuracy: 0.9999\n",
      "Epoch 66/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 7.7586e-04 - masked_accuracy: 0.9998\n",
      "Epoch 67/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 8.2731e-04 - masked_accuracy: 0.9998\n",
      "Epoch 68/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0027 - masked_accuracy: 0.9993\n",
      "Epoch 69/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0032 - masked_accuracy: 0.9993\n",
      "Epoch 70/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0026 - masked_accuracy: 0.9992\n",
      "Epoch 71/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0019 - masked_accuracy: 0.9999\n",
      "Epoch 72/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0023 - masked_accuracy: 0.9993\n",
      "Epoch 73/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0016 - masked_accuracy: 0.9996\n",
      "Epoch 74/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0014 - masked_accuracy: 0.9996\n",
      "Epoch 75/75\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0014 - masked_accuracy: 0.9998\n",
      "---------------------------- Using model ----------------------------\n",
      "Generating output for sequence 0\n",
      "Generating output for sequence 1\n",
      "Generating output for sequence 2\n",
      "Generating output for sequence 3\n",
      "Generating output for sequence 4\n",
      "Generating output for sequence 5\n",
      "Generating output for sequence 6\n",
      "Generating output for sequence 7\n",
      "Generating output for sequence 8\n",
      "Generating output for sequence 9\n",
      "Generating output for sequence 10\n",
      "Generating output for sequence 11\n",
      "Generating output for sequence 12\n",
      "Generating output for sequence 13\n",
      "Generating output for sequence 14\n",
      "Generating output for sequence 15\n",
      "Generating output for sequence 16\n",
      "Generating output for sequence 17\n",
      "Generating output for sequence 18\n",
      "Generating output for sequence 19\n",
      "Generating output for sequence 20\n",
      "Generating output for sequence 21\n",
      "Generating output for sequence 22\n",
      "Generating output for sequence 23\n",
      "Generating output for sequence 24\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(train=True, \n",
    "         compute_results=True, \n",
    "         n_conds=-1,\n",
    "         n_samples=25,\n",
    "         epochs=75)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
