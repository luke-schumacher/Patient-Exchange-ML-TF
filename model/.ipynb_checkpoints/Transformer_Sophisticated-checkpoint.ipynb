{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b1f1f0b-04c3-4453-8bd0-61a904b48a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca8a9abf-a16d-4db2-8f2f-0ee6f95b72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11', 2: 'MRI_EXU_95', 3: 'MRI_FRR_18', 4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264', 6: 'MRI_FRR_3', 7: 'MRI_FRR_34', 8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100', 10: 'MRI_MSR_104', 11: 'MRI_MSR_21', 12: 'MRI_MSR_34',\n",
    "    0: 'PADDED',  # Add a padding category\n",
    "    10: 'START',  # Start token\n",
    "    9: 'END'      # End token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56f24bff-9b20-4665-8ea2-73708759b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model) // 2)) / np.float32(d_model))\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc2420f7-ac3b-4e96-99be-0596d1b12e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MultiHeadAttention Layer\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        attention = tf.reshape(attention, (batch_size, -1, self.d_model))\n",
    "        return self.dense(attention)\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3f1db13d-591f-4c18-9578-9d7e2178ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positionwise Feedforward Layer\n",
    "class PositionwiseFeedforward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dense1 = Dense(dff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Define Transformer Block\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output = self.att(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "# Define Encoder Layer\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        return x\n",
    "\n",
    "# Define Decoder Layer\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "757a4aff-c1ce-426b-ae8e-5da424d01a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedforward(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # Ensure training, mask passed as keywords\n",
    "        attn_output = self.att(x, x, x, mask)  # x already contains embeddings\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74c56e84-e57b-4f4e-ad09-919e21c802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.enc_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=None, mask=None):  # training and mask as keyword arguments\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7faca35-5da9-450b-93c7-bd61ef368962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.dec_layers = [TransformerBlock(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, enc_output, training=None, look_ahead_mask=None, padding_mask=None):  # Ensure keyword args\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, training=training, mask=look_ahead_mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8503c952-f418-4b96-9256-de552f34558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, targets, training=None, look_ahead_mask=None, padding_mask=None):\n",
    "        enc_output = self.encoder(inputs, training=training, mask=padding_mask)\n",
    "        dec_output = self.decoder(targets, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f80f098f-5cf7-4270-8635-c1d284e0d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(directory, encoding_legend):\n",
    "    all_blocks = []\n",
    "    all_source_ids = np.array(list(encoding_legend.keys())).reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(all_source_ids)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            block = pd.read_csv(file_path)\n",
    "\n",
    "            assert block.shape == (36, 5), f\"Block {filename} has an unexpected shape {block.shape}\"\n",
    "\n",
    "            source_ids = block[['sourceID']].values.reshape(-1, 1)\n",
    "            one_hot_encoded_sourceID = encoder.transform(source_ids)\n",
    "\n",
    "            # Normalize additional features\n",
    "            timediff = block[['timediff']].values\n",
    "            ptab = np.nan_to_num(block[['PTAB']].values)\n",
    "            timediff = (timediff - np.mean(timediff)) / np.std(timediff)\n",
    "            ptab = (ptab - np.mean(ptab)) / np.std(ptab)\n",
    "            body_group_from = block[['BodyGroup_from']].values\n",
    "            body_group_to = block[['BodyGroup_to']].values\n",
    "\n",
    "            # Create input block with start and end tokens\n",
    "            X_block = np.concatenate((one_hot_encoded_sourceID, timediff, ptab, body_group_from, body_group_to), axis=1)\n",
    "            all_blocks.append(X_block)\n",
    "\n",
    "    all_blocks = np.stack(all_blocks, axis=0)\n",
    "    return all_blocks, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "da9a3972-344e-4087-ad19-9dbd56b5d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the 150 CSV data blocks\n",
    "data_directory = \"../data/filtered_blocks_padded/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7300fa33-e507-4ce2-a127-c650363c78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data and obtain one-hot encoding for sourceIDs\n",
    "all_blocks, encoder = preprocess_data(data_directory, encoding_legend)\n",
    "\n",
    "# Parameters for model\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "input_vocab_size = len(encoder.categories_[0])  # Number of unique sourceIDs\n",
    "target_vocab_size = input_vocab_size  # Assuming prediction is similar to input\n",
    "pe_input = 1000\n",
    "pe_target = 1000\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b6ae9a0-fb85-4416-bbef-808d5a83cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer model\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, dropout_rate)\n",
    "transformer.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07c0efc5-d222-482f-8d7c-789ae6f4ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input (creating dummy data for testing)\n",
    "# Adjust batch size based on your data length\n",
    "batch_size = min(32, len(df) // 2)  # Ensure at least some data for batching\n",
    "max_seq_length = 36  # Adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e0137e00-3b39-4bf2-99ea-59c4544b48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy input and target sequences (for illustration)\n",
    "inputs = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=input_vocab_size)\n",
    "targets = tf.random.uniform((batch_size, max_seq_length), dtype=tf.int64, minval=0, maxval=target_vocab_size)\n",
    "look_ahead_mask = None\n",
    "padding_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf55e234-7c56-4ee3-bbb4-0a5b083c9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 34, 13)\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass\n",
    "output = transformer(inputs=inputs, targets=targets, training=True, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "print(output.shape)  # Should now work correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c6bc859b-feba-4929-80d5-28bc8033eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))  # Mask out padding tokens\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7c812bd-387f-4556-a213-4090cc41fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded padded_block_1.csv, shape: (36, 5)\n",
      "Loaded padded_block_10.csv, shape: (36, 5)\n",
      "Loaded padded_block_100.csv, shape: (36, 5)\n",
      "Loaded padded_block_101.csv, shape: (36, 5)\n",
      "Loaded padded_block_102.csv, shape: (36, 5)\n",
      "Loaded padded_block_103.csv, shape: (36, 5)\n",
      "Loaded padded_block_104.csv, shape: (36, 5)\n",
      "Loaded padded_block_105.csv, shape: (36, 5)\n",
      "Loaded padded_block_106.csv, shape: (36, 5)\n",
      "Loaded padded_block_107.csv, shape: (36, 5)\n",
      "Loaded padded_block_108.csv, shape: (36, 5)\n",
      "Loaded padded_block_109.csv, shape: (36, 5)\n",
      "Loaded padded_block_11.csv, shape: (36, 5)\n",
      "Loaded padded_block_110.csv, shape: (36, 5)\n",
      "Loaded padded_block_111.csv, shape: (36, 5)\n",
      "Loaded padded_block_112.csv, shape: (36, 5)\n",
      "Loaded padded_block_113.csv, shape: (36, 5)\n",
      "Loaded padded_block_114.csv, shape: (36, 5)\n",
      "Loaded padded_block_115.csv, shape: (36, 5)\n",
      "Loaded padded_block_116.csv, shape: (36, 5)\n",
      "Loaded padded_block_117.csv, shape: (36, 5)\n",
      "Loaded padded_block_118.csv, shape: (36, 5)\n",
      "Loaded padded_block_119.csv, shape: (36, 5)\n",
      "Loaded padded_block_12.csv, shape: (36, 5)\n",
      "Loaded padded_block_120.csv, shape: (36, 5)\n",
      "Loaded padded_block_121.csv, shape: (36, 5)\n",
      "Loaded padded_block_122.csv, shape: (36, 5)\n",
      "Loaded padded_block_123.csv, shape: (36, 5)\n",
      "Loaded padded_block_124.csv, shape: (36, 5)\n",
      "Loaded padded_block_125.csv, shape: (36, 5)\n",
      "Loaded padded_block_126.csv, shape: (36, 5)\n",
      "Loaded padded_block_127.csv, shape: (36, 5)\n",
      "Loaded padded_block_128.csv, shape: (36, 5)\n",
      "Loaded padded_block_129.csv, shape: (36, 5)\n",
      "Loaded padded_block_13.csv, shape: (36, 5)\n",
      "Loaded padded_block_130.csv, shape: (36, 5)\n",
      "Loaded padded_block_131.csv, shape: (36, 5)\n",
      "Loaded padded_block_132.csv, shape: (36, 5)\n",
      "Loaded padded_block_133.csv, shape: (36, 5)\n",
      "Loaded padded_block_134.csv, shape: (36, 5)\n",
      "Loaded padded_block_135.csv, shape: (36, 5)\n",
      "Loaded padded_block_136.csv, shape: (36, 5)\n",
      "Loaded padded_block_137.csv, shape: (36, 5)\n",
      "Loaded padded_block_138.csv, shape: (36, 5)\n",
      "Loaded padded_block_139.csv, shape: (36, 5)\n",
      "Loaded padded_block_14.csv, shape: (36, 5)\n",
      "Loaded padded_block_140.csv, shape: (36, 5)\n",
      "Loaded padded_block_141.csv, shape: (36, 5)\n",
      "Loaded padded_block_142.csv, shape: (36, 5)\n",
      "Loaded padded_block_143.csv, shape: (36, 5)\n",
      "Loaded padded_block_144.csv, shape: (36, 5)\n",
      "Loaded padded_block_145.csv, shape: (36, 5)\n",
      "Loaded padded_block_146.csv, shape: (36, 5)\n",
      "Loaded padded_block_147.csv, shape: (36, 5)\n",
      "Loaded padded_block_148.csv, shape: (36, 5)\n",
      "Loaded padded_block_149.csv, shape: (36, 5)\n",
      "Loaded padded_block_15.csv, shape: (36, 5)\n",
      "Loaded padded_block_150.csv, shape: (36, 5)\n",
      "Loaded padded_block_16.csv, shape: (36, 5)\n",
      "Loaded padded_block_17.csv, shape: (36, 5)\n",
      "Loaded padded_block_18.csv, shape: (36, 5)\n",
      "Loaded padded_block_19.csv, shape: (36, 5)\n",
      "Loaded padded_block_2.csv, shape: (36, 5)\n",
      "Loaded padded_block_20.csv, shape: (36, 5)\n",
      "Loaded padded_block_21.csv, shape: (36, 5)\n",
      "Loaded padded_block_22.csv, shape: (36, 5)\n",
      "Loaded padded_block_23.csv, shape: (36, 5)\n",
      "Loaded padded_block_24.csv, shape: (36, 5)\n",
      "Loaded padded_block_25.csv, shape: (36, 5)\n",
      "Loaded padded_block_26.csv, shape: (36, 5)\n",
      "Loaded padded_block_27.csv, shape: (36, 5)\n",
      "Loaded padded_block_28.csv, shape: (36, 5)\n",
      "Loaded padded_block_29.csv, shape: (36, 5)\n",
      "Loaded padded_block_3.csv, shape: (36, 5)\n",
      "Loaded padded_block_30.csv, shape: (36, 5)\n",
      "Loaded padded_block_31.csv, shape: (36, 5)\n",
      "Loaded padded_block_32.csv, shape: (36, 5)\n",
      "Loaded padded_block_33.csv, shape: (36, 5)\n",
      "Loaded padded_block_34.csv, shape: (36, 5)\n",
      "Loaded padded_block_35.csv, shape: (36, 5)\n",
      "Loaded padded_block_36.csv, shape: (36, 5)\n",
      "Loaded padded_block_37.csv, shape: (36, 5)\n",
      "Loaded padded_block_38.csv, shape: (36, 5)\n",
      "Loaded padded_block_39.csv, shape: (36, 5)\n",
      "Loaded padded_block_4.csv, shape: (36, 5)\n",
      "Loaded padded_block_40.csv, shape: (36, 5)\n",
      "Loaded padded_block_41.csv, shape: (36, 5)\n",
      "Loaded padded_block_42.csv, shape: (36, 5)\n",
      "Loaded padded_block_43.csv, shape: (36, 5)\n",
      "Loaded padded_block_44.csv, shape: (36, 5)\n",
      "Loaded padded_block_45.csv, shape: (36, 5)\n",
      "Loaded padded_block_46.csv, shape: (36, 5)\n",
      "Loaded padded_block_47.csv, shape: (36, 5)\n",
      "Loaded padded_block_48.csv, shape: (36, 5)\n",
      "Loaded padded_block_49.csv, shape: (36, 5)\n",
      "Loaded padded_block_5.csv, shape: (36, 5)\n",
      "Loaded padded_block_50.csv, shape: (36, 5)\n",
      "Loaded padded_block_51.csv, shape: (36, 5)\n",
      "Loaded padded_block_52.csv, shape: (36, 5)\n",
      "Loaded padded_block_53.csv, shape: (36, 5)\n",
      "Loaded padded_block_54.csv, shape: (36, 5)\n",
      "Loaded padded_block_55.csv, shape: (36, 5)\n",
      "Loaded padded_block_56.csv, shape: (36, 5)\n",
      "Loaded padded_block_57.csv, shape: (36, 5)\n",
      "Loaded padded_block_58.csv, shape: (36, 5)\n",
      "Loaded padded_block_59.csv, shape: (36, 5)\n",
      "Loaded padded_block_6.csv, shape: (36, 5)\n",
      "Loaded padded_block_60.csv, shape: (36, 5)\n",
      "Loaded padded_block_61.csv, shape: (36, 5)\n",
      "Loaded padded_block_62.csv, shape: (36, 5)\n",
      "Loaded padded_block_63.csv, shape: (36, 5)\n",
      "Loaded padded_block_64.csv, shape: (36, 5)\n",
      "Loaded padded_block_65.csv, shape: (36, 5)\n",
      "Loaded padded_block_66.csv, shape: (36, 5)\n",
      "Loaded padded_block_67.csv, shape: (36, 5)\n",
      "Loaded padded_block_68.csv, shape: (36, 5)\n",
      "Loaded padded_block_69.csv, shape: (36, 5)\n",
      "Loaded padded_block_7.csv, shape: (36, 5)\n",
      "Loaded padded_block_70.csv, shape: (36, 5)\n",
      "Loaded padded_block_71.csv, shape: (36, 5)\n",
      "Loaded padded_block_72.csv, shape: (36, 5)\n",
      "Loaded padded_block_73.csv, shape: (36, 5)\n",
      "Loaded padded_block_74.csv, shape: (36, 5)\n",
      "Loaded padded_block_75.csv, shape: (36, 5)\n",
      "Loaded padded_block_76.csv, shape: (36, 5)\n",
      "Loaded padded_block_77.csv, shape: (36, 5)\n",
      "Loaded padded_block_78.csv, shape: (36, 5)\n",
      "Loaded padded_block_79.csv, shape: (36, 5)\n",
      "Loaded padded_block_8.csv, shape: (36, 5)\n",
      "Loaded padded_block_80.csv, shape: (36, 5)\n",
      "Loaded padded_block_81.csv, shape: (36, 5)\n",
      "Loaded padded_block_82.csv, shape: (36, 5)\n",
      "Loaded padded_block_83.csv, shape: (36, 5)\n",
      "Loaded padded_block_84.csv, shape: (36, 5)\n",
      "Loaded padded_block_85.csv, shape: (36, 5)\n",
      "Loaded padded_block_86.csv, shape: (36, 5)\n",
      "Loaded padded_block_87.csv, shape: (36, 5)\n",
      "Loaded padded_block_88.csv, shape: (36, 5)\n",
      "Loaded padded_block_89.csv, shape: (36, 5)\n",
      "Loaded padded_block_9.csv, shape: (36, 5)\n",
      "Loaded padded_block_90.csv, shape: (36, 5)\n",
      "Loaded padded_block_91.csv, shape: (36, 5)\n",
      "Loaded padded_block_92.csv, shape: (36, 5)\n",
      "Loaded padded_block_93.csv, shape: (36, 5)\n",
      "Loaded padded_block_94.csv, shape: (36, 5)\n",
      "Loaded padded_block_95.csv, shape: (36, 5)\n",
      "Loaded padded_block_96.csv, shape: (36, 5)\n",
      "Loaded padded_block_97.csv, shape: (36, 5)\n",
      "Loaded padded_block_98.csv, shape: (36, 5)\n",
      "Loaded padded_block_99.csv, shape: (36, 5)\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        NaN               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0  -256950.0               1            11\n",
      "1        12       5.0  -256950.0               1            11\n",
      "2         4       7.0 -1168050.0               1            11\n",
      "3         5      14.0 -1168050.0               1            11\n",
      "4         1      24.0 -1168050.0               1            11\n",
      "DataFrame size: (36, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the directory containing the data blocks\n",
    "data_directory = \"../data/filtered_blocks_padded/\"\n",
    "\n",
    "# Initialize an empty list to hold all DataFrames\n",
    "data_frames = []\n",
    "\n",
    "for file_name in os.listdir(data_directory):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {file_name}, shape: {df.shape}\")\n",
    "\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one DataFrame\n",
    "combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Check the first few rows of the combined data\n",
    "print(combined_data.head())\n",
    "\n",
    "# Ensure the DataFrame is loaded properly\n",
    "print(df.head())\n",
    "print(f\"DataFrame size: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b404619-8512-4026-b707-7e0c35f5a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Dataset size: 1\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Dataset size: 1\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the preprocessing function\n",
    "def preprocess_data(df, sequence_length, step_size=1):\n",
    "    inputs = df['sourceID'].values\n",
    "    targets = df['sourceID'].shift(-1).fillna(0).values  # Shift by 1 and replace NaN with 0\n",
    "\n",
    "    # Convert to integer type for model input\n",
    "    inputs = inputs.astype(int)\n",
    "    targets = targets.astype(int)\n",
    "\n",
    "    input_sequences = []\n",
    "    target_sequences = []\n",
    "\n",
    "    # Slide over the entire dataset with overlapping windows\n",
    "    for i in range(0, len(inputs) - sequence_length + 1, step_size):  # Added step_size for overlap\n",
    "        input_sequences.append(inputs[i:i + sequence_length])\n",
    "        target_sequences.append(targets[i:i + sequence_length])\n",
    "\n",
    "    inputs = np.array(input_sequences)\n",
    "    targets = np.array(target_sequences)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "sequence_length = 36  # Example sequence length\n",
    "inputs, targets = preprocess_data(df, sequence_length)\n",
    "print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "# Create a dataset from the inputs and targets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "\n",
    "# Create a dataset with a proper batch size\n",
    "dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "\n",
    "# Print the dataset size to ensure it's not empty\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Check inputs and targets before reshaping\n",
    "inputs, targets = preprocess_data(df, sequence_length)\n",
    "print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "if inputs.size > 0 and targets.size > 0:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "else:\n",
    "    print(\"No sequences generated. Dataset size is 0.\")\n",
    "\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch_inputs, batch_targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(batch_inputs, batch_targets, training=True, look_ahead_mask=None, padding_mask=None)\n",
    "        loss = loss_function(batch_targets, predictions)  # Ensure loss_function is defined\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    return loss  # Make sure this returns the loss\n",
    "    print(f\"Loss: {loss.numpy()}\")\n",
    "    print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "263c2ab9-1b06-4c3f-b5f8-6e614f0431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2a524ca-bbc6-474e-a903-4e8c6c191dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:731: UserWarning: Gradients do not exist for variables ['embeddings', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8467180728912354\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 2, Loss: 0.9396485090255737\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 3, Loss: 0.9706689119338989\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 4, Loss: 0.8385770916938782\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 5, Loss: 0.7982547283172607\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 6, Loss: 0.8374862670898438\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 7, Loss: 0.7619124054908752\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 8, Loss: 0.7308480739593506\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 9, Loss: 0.7428252696990967\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 10, Loss: 0.7760189771652222\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 11, Loss: 0.7136896848678589\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 12, Loss: 0.7402427196502686\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 13, Loss: 0.6991826295852661\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 14, Loss: 0.6971650123596191\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 15, Loss: 0.7022903561592102\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 16, Loss: 0.7394987344741821\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 17, Loss: 0.7232686877250671\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 18, Loss: 0.7145892381668091\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 19, Loss: 0.6761232614517212\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 20, Loss: 0.7019459009170532\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 21, Loss: 0.7043846249580383\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 22, Loss: 0.6917494535446167\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 23, Loss: 0.6657365560531616\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 24, Loss: 0.6928709745407104\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 25, Loss: 0.682864785194397\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 26, Loss: 0.7153420448303223\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 27, Loss: 0.6770499348640442\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 28, Loss: 0.6747408509254456\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 29, Loss: 0.667184591293335\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 30, Loss: 0.6769161224365234\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 31, Loss: 0.7082902193069458\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 32, Loss: 0.6862292885780334\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 33, Loss: 0.6919901371002197\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 34, Loss: 0.6929512023925781\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 35, Loss: 0.7106062769889832\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 36, Loss: 0.719326913356781\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 37, Loss: 0.7124058604240417\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 38, Loss: 0.6857633590698242\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 39, Loss: 0.7106481790542603\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 40, Loss: 0.6568699479103088\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 41, Loss: 0.6700533628463745\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 42, Loss: 0.6716439723968506\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 43, Loss: 0.7031249403953552\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 44, Loss: 0.6770345568656921\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 45, Loss: 0.6817432641983032\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 46, Loss: 0.6610156893730164\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 47, Loss: 0.6731368899345398\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 48, Loss: 0.7111388444900513\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 49, Loss: 0.6815941333770752\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 50, Loss: 0.6904681921005249\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 51, Loss: 0.6843454241752625\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 52, Loss: 0.7195090055465698\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 53, Loss: 0.7121697068214417\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 54, Loss: 0.7099160552024841\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 55, Loss: 0.686141312122345\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 56, Loss: 0.6717679500579834\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 57, Loss: 0.6666271090507507\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 58, Loss: 0.671220064163208\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 59, Loss: 0.677607536315918\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 60, Loss: 0.6494401097297668\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 61, Loss: 0.7248237133026123\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 62, Loss: 0.6684199571609497\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 63, Loss: 0.6973879337310791\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 64, Loss: 0.6456335783004761\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 65, Loss: 0.6143490672111511\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 66, Loss: 0.6287493109703064\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 67, Loss: 0.5913379192352295\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 68, Loss: 0.5110061168670654\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 69, Loss: 0.44556373357772827\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 70, Loss: 0.4349714517593384\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 71, Loss: 0.42509448528289795\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 72, Loss: 0.38015854358673096\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 73, Loss: 0.3860935568809509\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 74, Loss: 0.3454550504684448\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 75, Loss: 0.4583197832107544\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 76, Loss: 0.3511689305305481\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 77, Loss: 0.3850410580635071\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 78, Loss: 0.33757779002189636\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 79, Loss: 0.3770839273929596\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 80, Loss: 1.1413867473602295\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 81, Loss: 0.39464491605758667\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 82, Loss: 0.4087807536125183\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 83, Loss: 0.7512152194976807\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 84, Loss: 0.8166622519493103\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 85, Loss: 0.4724676311016083\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 86, Loss: 0.4503607749938965\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 87, Loss: 0.4504261612892151\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 88, Loss: 0.409719318151474\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 89, Loss: 0.4507525861263275\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 90, Loss: 0.473909854888916\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 91, Loss: 0.431629478931427\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 92, Loss: 0.4256514608860016\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 93, Loss: 0.4450114071369171\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 94, Loss: 0.43050652742385864\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 95, Loss: 0.40000927448272705\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 96, Loss: 0.42038020491600037\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 97, Loss: 0.3784928321838379\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 98, Loss: 0.3933912515640259\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 99, Loss: 0.38919198513031006\n",
      "Inputs shape: (1, 36), Targets shape: (1, 36)\n",
      "Epoch 100, Loss: 0.4017525911331177\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_inputs, batch_targets in dataset:\n",
    "        print(f\"Inputs shape: {batch_inputs.shape}, Targets shape: {batch_targets.shape}\")\n",
    "        \n",
    "        # Ensure the shapes are correct for your model\n",
    "        batch_inputs = tf.reshape(batch_inputs, [batch_size, -1])\n",
    "        batch_targets = tf.reshape(batch_targets, [batch_size, -1])\n",
    "\n",
    "        # Get the loss from the train_step function\n",
    "        loss = train_step(batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    # Only print loss if dataset is not empty\n",
    "    if len(dataset) > 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataset)}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch + 1}, No batches to train on.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b35bc5ae-e467-40ae-8b02-839ab8445d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sequence 1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Final predicted sequence (no padding): [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Raw predictions: [[[ 9.825667   -0.05095122  0.6581158  -1.7611328   1.319873\n",
      "   -0.9963672  -1.2683365  -2.000377    3.4743962   0.42679703\n",
      "   -4.92955    -2.562101    1.1111085 ]\n",
      "  [ 9.818416   -0.04262967  0.64864105 -1.7706294   1.3244077\n",
      "   -1.0026122  -1.2750347  -1.997112    3.4788451   0.43114388\n",
      "   -4.93283    -2.5613554   1.09867   ]\n",
      "  [ 9.816545   -0.03586858  0.6364845  -1.7821568   1.3316162\n",
      "   -1.0042572  -1.2747132  -2.0039418   3.4856665   0.4276878\n",
      "   -4.9333706  -2.5608547   1.0967886 ]\n",
      "  [ 9.81983    -0.03541658  0.6278577  -1.7880647   1.3373626\n",
      "   -1.0036463  -1.2713563  -2.011396    3.4927137   0.41948056\n",
      "   -4.932775   -2.55975     1.1054902 ]\n",
      "  [ 9.823911   -0.03895711  0.6276505  -1.7850211   1.3410151\n",
      "   -1.0040203  -1.2674804  -2.016428    3.4966168   0.41261497\n",
      "   -4.9319763  -2.5569158   1.1172144 ]\n",
      "  [ 9.825056   -0.04214796  0.63553244 -1.7787026   1.3401289\n",
      "   -1.0049042  -1.2646855  -2.0120578   3.4959605   0.41383743\n",
      "   -4.9339347  -2.550485    1.1269675 ]\n",
      "  [ 9.823113   -0.04272211  0.6465862  -1.7702837   1.3325788\n",
      "   -1.0023916  -1.2673169  -2.00279     3.4954963   0.42243645\n",
      "   -4.938172   -2.5439548   1.1284024 ]\n",
      "  [ 9.820899   -0.04079709  0.65226954 -1.7662177   1.3278865\n",
      "   -1.0020981  -1.2701929  -1.9967592   3.4935024   0.431606\n",
      "   -4.9401307  -2.5398135   1.1238753 ]\n",
      "  [ 9.82009    -0.03994182  0.6486859  -1.7703956   1.3289496\n",
      "   -1.0024221  -1.2671787  -2.0050752   3.4892993   0.43551192\n",
      "   -4.9360228  -2.5422137   1.1243939 ]\n",
      "  [ 9.820754   -0.04148093  0.641639   -1.7773719   1.3318999\n",
      "   -1.005169   -1.2579893  -2.0238426   3.4847095   0.434591\n",
      "   -4.9277253  -2.5512016   1.1278572 ]\n",
      "  [ 9.825062   -0.04636648  0.63998777 -1.7798173   1.3313181\n",
      "   -1.0083512  -1.2436478  -2.0423148   3.4825878   0.42806312\n",
      "   -4.919103   -2.560943    1.1295109 ]\n",
      "  [ 9.831017   -0.05416866  0.6432482  -1.7784314   1.3261173\n",
      "   -1.007846   -1.2340853  -2.0486147   3.4852746   0.42346564\n",
      "   -4.9160347  -2.569016    1.1287646 ]\n",
      "  [ 9.836749   -0.05789721  0.6503214  -1.7724863   1.3174704\n",
      "   -1.0075487  -1.2323955  -2.037259    3.4903257   0.4270364\n",
      "   -4.917003   -2.5676572   1.123601  ]\n",
      "  [ 9.839181   -0.05256002  0.6555522  -1.7648591   1.308836\n",
      "   -1.0086391  -1.2377722  -2.022018    3.4939363   0.4351923\n",
      "   -4.917808   -2.5609848   1.1147754 ]\n",
      "  [ 9.839763   -0.04416548  0.6566075  -1.7593292   1.3038499\n",
      "   -1.0105798  -1.2463163  -2.0134137   3.4946601   0.44060203\n",
      "   -4.9151115  -2.5529432   1.1103445 ]\n",
      "  [ 9.840861   -0.03769323  0.6518927  -1.7566682   1.3038316\n",
      "   -1.0131592  -1.2509934  -2.0099812   3.493361    0.4420958\n",
      "   -4.908149   -2.5501072   1.1112331 ]\n",
      "  [ 9.843307   -0.03307499  0.64627784 -1.7561389   1.3069605\n",
      "   -1.0176388  -1.2559015  -2.0107496   3.4937546   0.44039738\n",
      "   -4.8993087  -2.5542457   1.114209  ]\n",
      "  [ 9.845496   -0.03171211  0.642628   -1.7579263   1.3124206\n",
      "   -1.0211288  -1.2626046  -2.0108042   3.495146    0.43710408\n",
      "   -4.892615   -2.5640838   1.1175406 ]\n",
      "  [ 9.8430805  -0.03697432  0.64459693 -1.7639458   1.3161321\n",
      "   -1.0180106  -1.2732073  -2.0044196   3.4970121   0.43671265\n",
      "   -4.9003015  -2.5756323   1.1201512 ]\n",
      "  [ 9.833243   -0.04425963  0.64937097 -1.771824    1.31471\n",
      "   -1.005835   -1.2783943  -1.9955297   3.5009024   0.439113\n",
      "   -4.9192     -2.579298    1.1181996 ]\n",
      "  [ 9.826531   -0.0514188   0.6520166  -1.781717    1.3140842\n",
      "   -0.9910722  -1.2736307  -1.99146     3.5051303   0.43903545\n",
      "   -4.933175   -2.5734463   1.1188691 ]\n",
      "  [ 9.826162   -0.0548576   0.6535237  -1.7885461   1.3142928\n",
      "   -0.98253065 -1.2612494  -1.9931105   3.5038764   0.43437538\n",
      "   -4.9331183  -2.5633655   1.1229095 ]\n",
      "  [ 9.83067    -0.05634348  0.6586531  -1.7887454   1.3141971\n",
      "   -0.98024815 -1.249282   -1.996767    3.4983683   0.42907628\n",
      "   -4.9229155  -2.5532415   1.127012  ]\n",
      "  [ 9.835538   -0.0578412   0.6678354  -1.7837993   1.3127823\n",
      "   -0.98524183 -1.2411298  -1.997777    3.4899354   0.42374068\n",
      "   -4.9096475  -2.5470011   1.1246881 ]\n",
      "  [ 9.839186   -0.06134696  0.6777461  -1.7728994   1.3101896\n",
      "   -0.9979532  -1.2378362  -1.9925358   3.4829338   0.4223751\n",
      "   -4.896146   -2.5430393   1.1147373 ]\n",
      "  [ 9.840608   -0.06660998  0.68406826 -1.7616515   1.3082643\n",
      "   -1.0089494  -1.2402377  -1.9811262   3.4788995   0.4291931\n",
      "   -4.8921623  -2.5426676   1.1027993 ]\n",
      "  [ 9.839283   -0.06932063  0.6833079  -1.7559397   1.3098902\n",
      "   -1.0152011  -1.2468969  -1.9750342   3.4785206   0.43922377\n",
      "   -4.899546   -2.542494    1.0998278 ]\n",
      "  [ 9.835937   -0.0685326   0.67795604 -1.7536341   1.3117917\n",
      "   -1.0179203  -1.2537683  -1.9750541   3.4796052   0.44806632\n",
      "   -4.9110436  -2.540208    1.1056566 ]\n",
      "  [ 9.834822   -0.06550397  0.6719797  -1.746981    1.3134623\n",
      "   -1.0195664  -1.2564327  -1.9786531   3.4806888   0.45146865\n",
      "   -4.9162545  -2.5357196   1.1173593 ]\n",
      "  [ 9.8354645  -0.06225994  0.6676224  -1.7419013   1.3172741\n",
      "   -1.0202246  -1.2551101  -1.9826937   3.4774826   0.45263594\n",
      "   -4.9148707  -2.5289016   1.1302617 ]\n",
      "  [ 9.836604   -0.05916208  0.6620023  -1.7422509   1.3220285\n",
      "   -1.0188587  -1.2530308  -1.9814571   3.4712296   0.45441884\n",
      "   -4.9091573  -2.5244517   1.1361581 ]\n",
      "  [ 9.838869   -0.05610927  0.6561216  -1.7454839   1.3259755\n",
      "   -1.0151106  -1.2507375  -1.9715298   3.4664247   0.45478052\n",
      "   -4.900628   -2.5223415   1.1318916 ]\n",
      "  [ 9.839288   -0.05505779  0.6504217  -1.7506948   1.3268255\n",
      "   -1.0135862  -1.2482438  -1.9621576   3.466925    0.45258325\n",
      "   -4.898351   -2.5291743   1.1255511 ]\n",
      "  [ 9.841427   -0.05846722  0.6460803  -1.7563184   1.3260338\n",
      "   -1.0140679  -1.2397865  -1.963153    3.470736    0.44744453\n",
      "   -4.901587   -2.5374055   1.1255513 ]\n",
      "  [ 9.845553   -0.0656132   0.6451393  -1.7581758   1.3261105\n",
      "   -1.015101   -1.2308316  -1.9685514   3.4748151   0.44099325\n",
      "   -4.90454    -2.5451987   1.1319562 ]\n",
      "  [ 9.849986   -0.07108377  0.64963204 -1.7525207   1.3231286\n",
      "   -1.0180486  -1.2266561  -1.9693878   3.4792576   0.43366623\n",
      "   -4.9054227  -2.5488026   1.1371931 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Sample input, ensure it matches the expected shape (batch_size, sequence_length)\n",
    "sample_inputs = np.array([[10, 4, 5, 1, 12, 8, 9]])  \n",
    "sample_inputs = tf.convert_to_tensor(sample_inputs)\n",
    "\n",
    "# Pad the inputs to match the expected input length of 36\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(sample_inputs, maxlen=36, padding='post')\n",
    "\n",
    "# Reshape padded inputs for batch size of 1\n",
    "padded_inputs = tf.expand_dims(padded_inputs, axis=0)  # Now shape (1, 36)\n",
    "\n",
    "# Make predictions\n",
    "predictions = transformer(padded_inputs, targets=tf.zeros((1, 36)), training=False, look_ahead_mask=None, padding_mask=None)\n",
    "\n",
    "# Convert predictions from logits to class indices\n",
    "predicted_indices = tf.argmax(predictions, axis=-1).numpy()\n",
    "\n",
    "# Print the predicted sequences\n",
    "for i, seq in enumerate(predicted_indices):\n",
    "    print(f\"Predicted sequence {i + 1}: {seq}\")\n",
    "\n",
    "# Remove padding (optional)\n",
    "predicted_sequence = np.where(seq == 0, -1, seq)  # Replace 0 (PADDED) with -1 or another value\n",
    "print(f\"Final predicted sequence (no padding): {predicted_sequence}\")\n",
    "print(\"Raw predictions:\", predictions.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a463857-6a4a-413b-948b-56019d2696af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc0f76-c612-449d-b720-0fb7788c21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
