{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52984ef-399a-482a-9f4a-aa1f8b9b0b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15304c14-cf87-4a5d-8c71-22d0fb9ec508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "learning_rate = 0.01\n",
    "key_dim = 16\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f61e6d-43e0-412a-854a-fa1c92840451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/encoded_176398_HEAD.csv.\n",
      "\n",
      "First 5 rows of the dataset before any processing:\n",
      "              datetime  sourceID  timediff  ZAxisInPossible  ZAxisOutPossible  \\\n",
      "0  2023-03-27 08:14:34        10       0.0              NaN               NaN   \n",
      "1  2023-03-27 08:14:49         4      15.0              NaN               NaN   \n",
      "2  2023-03-27 08:14:56         5      22.0              1.0               0.0   \n",
      "3  2023-03-27 08:15:08         1      34.0              1.0               0.0   \n",
      "4  2023-03-27 08:15:39        12      65.0              1.0               0.0   \n",
      "\n",
      "   YAxisDownPossible  YAxisUpPossible       PTAB  BC  S1  ...  C24  EN  SHL  \\\n",
      "0                NaN              NaN        NaN   0 NaN  ...  NaN NaN  NaN   \n",
      "1                NaN              NaN -1127700.0   0 NaN  ...  NaN NaN  NaN   \n",
      "2                1.0              1.0 -1127700.0   0 NaN  ...  NaN NaN  NaN   \n",
      "3                1.0              1.0 -1127700.0   1 NaN  ...  NaN NaN  NaN   \n",
      "4                1.0              1.0 -1127700.0   1 NaN  ...  NaN NaN  NaN   \n",
      "\n",
      "   SHS  BodyPart_from  BodyPart_to                            PatientID_from  \\\n",
      "0  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "1  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "2  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "3  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "4  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "\n",
      "                               PatientID_to  BodyGroup_from  BodyGroup_to  \n",
      "0  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "1  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "2  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "3  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "4  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the already encoded data\n",
    "file_path = \"../data/encoded_176398_HEAD.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Data loaded successfully from {file_path}.\\n\")\n",
    "print(\"First 5 rows of the dataset before any processing:\")\n",
    "print(df.head())  # Print first few rows to understand the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2dad6e-dc1d-44a1-85c6-6f9f54471a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unnecessary columns.\n",
      "Remaining columns: ['sourceID', 'timediff', 'PTAB', 'BodyGroup_from', 'BodyGroup_to']\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        NaN               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns (based on your latest specification)\n",
    "columns_to_drop = ['datetime', 'SN', 'ZAxisInPossible', 'ZAxisOutPossible', 'YAxisDownPossible', \n",
    "                   'YAxisUpPossible', 'BC', 'S1', 'S10', 'S11', 'S12', 'S2', 'S3', 'S4', \n",
    "                   'S5', 'S6', 'S7', 'S8', 'S9', 'BO1', 'BO2', 'BO3', 'B1', 'B2', 'B3', 'B4', \n",
    "                   'B5', 'HE2', 'HE4', 'NE2', 'HE1', 'HE3', 'NE1', 'SHA', 'HW1', 'HW2', 'HW3', \n",
    "                   '18K', 'FA', 'TO', 'BAL', 'BAR', 'BCL', 'BCR', 'HC2', 'HC4', 'HC6', 'HC7', \n",
    "                   'NC2', 'HC1', 'HC3', 'HC5', 'NC1', 'Na', 'UFL', 'PA1', 'PA2', 'PA3', 'PA4', \n",
    "                   'PA5', 'PA6', 'SP1', 'SP2', 'SP3', 'SP4', 'SP5', 'SP6', 'SP7', 'SP8', 'BL8', \n",
    "                   'BR8', 'UFS', 'HEA', 'HEP', 'SC', 'PeH', 'PeN', 'FS', 'FL', 'BY1', 'BY2', \n",
    "                   'BY3', 'BL', 'BR', 'HE', 'BL4', 'BR4', 'BL1', 'BR1', 'BL2', 'BR2', 'L7', \n",
    "                   'L4', 'H2L', 'N2L', 'H1U', 'N1U', 'He1', 'He2', 'TR1', 'TR2', 'TR3', 'TR4', \n",
    "                   'TR5', 'TR6', 'MR', 'ML', 'BL5', 'BR5', 'C24', 'EN', 'SHL', 'SHS','BodyPart_from', \n",
    "                   'BodyPart_to', 'PatientID_from', 'PatientID_to']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(\"Dropped unnecessary columns.\")\n",
    "print(\"Remaining columns:\", df.columns.tolist())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1397fae-e907-4020-b74b-3d16be7a0707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        0.0               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values with 0 in the DataFrame\n",
    "df.fillna(0, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1904656c-1090-4e8a-97d3-8f53cb5a1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target (sourceID)\n",
    "X = df.drop(columns=['sourceID'])\n",
    "y_sourceid = df['sourceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78bdf0b2-71d9-4890-bdc5-603a45a1c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few one-hot encoded 'sourceID' values:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Shape of one-hot encoded 'sourceID': (4501, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode 'sourceID'\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_sourceid_encoded = encoder.fit_transform(y_sourceid.values.reshape(-1, 1))\n",
    "original_sourceids = encoder.categories_[0]\n",
    "# Print the first few rows of y_sourceid_encoded to confirm one-hot encoding worked\n",
    "print(\"\\nFirst few one-hot encoded 'sourceID' values:\")\n",
    "print(y_sourceid_encoded[:5])\n",
    "print(\"Shape of one-hot encoded 'sourceID':\", y_sourceid_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ce7e72e-eb07-4a28-8e1d-f55f0755d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff40f546-c53a-4ede-882c-6a475efc375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sequence length of 5 for Transformer input\n",
    "sequence_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "655d282c-1adf-424f-8888-2f2032944cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(target[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X_sequences, y_sequences = create_sequences(X_scaled, y_sourceid_encoded, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f863f69-8264-4adc-834e-00ba1562ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder model\n",
    "def transformer_model(input_shape, output_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Embedding layer to transform input to higher dimensional space (if needed)\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    \n",
    "    # Multi-head attention layer\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
    "    \n",
    "    # Add & Norm\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
    "    \n",
    "    # Feedforward layer\n",
    "    ff_dim = 256  # You can adjust this dimension as needed\n",
    "    x_ffn = Dense(ff_dim, activation='relu')(x)\n",
    "    x_ffn = Dense(x.shape[-1])(x_ffn) \n",
    "    \n",
    "    # Final classification layer (softmax for multi-class)\n",
    "    outputs = Dense(output_dim, activation='softmax')(x[:, -1, :])  # Only last timestep output\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "108f88fd-26fb-4358-bf34-fdfa2b755cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "input_shape = (sequence_length, X_scaled.shape[1])\n",
    "output_dim = y_sourceid_encoded.shape[1]\n",
    "model = transformer_model(input_shape, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fed0869-09f8-467d-9320-851b7c1a1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccf9d9de-9dae-49e4-819a-e1cf0c2e777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.1802\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9244\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8650\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8545\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.8423\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8442\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8370\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8239\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8181\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8213\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8147\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8157\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8110\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8164\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8081\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7988\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8123\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7999\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7963\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7934\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7909\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7499\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7171\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.6927\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.6578\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6634\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6327\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6245\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6232\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6049\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5982\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5756\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5734\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5754\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5679\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5662\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5455\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5471\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5469\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5458\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5280\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5325\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5239\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5260\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 1.5123\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5142\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5151\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5088\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5063\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5027\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4959\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4906\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4953\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4813\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4775\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4703\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4718\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4689\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4617\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4543\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4572\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4604\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4560\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4528\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4576\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4386\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4430\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4363\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4484\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4308\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4337\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4338\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4386\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4268\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4156\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4228\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4178\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4180\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4028\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3991\n",
      "Epoch 81/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4030\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4078\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4019\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4029\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4123\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3943\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3956\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3969\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3954\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3872\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3871\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3828\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3783\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3694\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3738\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3831\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3746\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3749\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3848\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3730\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_sequences, y_sequences, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "400533ec-23a9-4c61-9526-c5405d77724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on training data\n",
    "predicted_sourceids = model.predict(X_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "866043f9-78b9-4156-97fd-d4c4b9823bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted probabilities back to class indices\n",
    "predicted_classes = np.argmax(predicted_sourceids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b74dde7-84af-4727-b4ad-9c317cc0ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few predicted sourceIDs:\n",
      "[[ 4]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot back to original sourceID using the encoder\n",
    "predicted_sourceids_final = encoder.inverse_transform(predicted_sourceids)\n",
    "# Print results\n",
    "print(\"\\nFirst few predicted sourceIDs:\")\n",
    "print(predicted_sourceids_final[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35aed398-e9d2-4d89-bb71-adb8cfda4ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_sourceids_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 27\u001b[0m\n\u001b[0;32m     11\u001b[0m encoding_legend \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRI_CCS_11\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRI_EXU_95\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;241m12\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRI_MSR_34\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Map predicted one-hot encodings to original sourceIDs\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m predicted_sourceids_final \u001b[38;5;241m=\u001b[39m map_onehot_to_sourceid(\u001b[43mpredicted_sourceids_onehot\u001b[49m, encoding_legend)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Print the final predicted sourceIDs\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst few predicted sourceIDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_sourceids_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to map one-hot encoded predictions back to sourceIDs\n",
    "def map_onehot_to_sourceid(onehot_predictions, encoding_legend):\n",
    "    sourceids = []\n",
    "    for prediction in onehot_predictions:\n",
    "        index = np.argmax(prediction)  # Find the index of the highest value\n",
    "        sourceid = encoding_legend[index + 1]  # Map back using the legend (1-based index)\n",
    "        sourceids.append(sourceid)\n",
    "    return sourceids\n",
    "\n",
    "# Encoding legend mapping (this is just a sample, adjust to your actual encoding legend)\n",
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11',\n",
    "    2: 'MRI_EXU_95',\n",
    "    3: 'MRI_FRR_18',\n",
    "    4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264',\n",
    "    6: 'MRI_FRR_3',\n",
    "    7: 'MRI_FRR_34',\n",
    "    8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100',\n",
    "    10: 'MRI_MSR_104',\n",
    "    11: 'MRI_MSR_21',\n",
    "    12: 'MRI_MSR_34'\n",
    "}\n",
    "\n",
    "# Map predicted one-hot encodings to original sourceIDs\n",
    "predicted_sourceids_final = map_onehot_to_sourceid(predicted_sourceids, encoding_legend)\n",
    "\n",
    "# Print the final predicted sourceIDs\n",
    "print(\"\\nFirst few predicted sourceIDs:\")\n",
    "print(predicted_sourceids_final[:16])\n",
    "\n",
    "# Optional: Save the predicted sourceIDs to a CSV file\n",
    "output_df = pd.DataFrame(predicted_sourceids_final, columns=[\"Predicted SourceID\"])\n",
    "output_df.to_csv(\"predicted_sourceids_final.csv\", index=False)\n",
    "print(\"Predicted sourceIDs saved to 'predicted_sourceids_final.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210a708-8072-4522-a832-f5c41db93dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
