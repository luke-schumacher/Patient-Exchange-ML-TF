{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a52984ef-399a-482a-9f4a-aa1f8b9b0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "15304c14-cf87-4a5d-8c71-22d0fb9ec508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "learning_rate = 0.01\n",
    "key_dim = 16\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83f61e6d-43e0-412a-854a-fa1c92840451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/encoded_176398_HEAD.csv.\n",
      "\n",
      "First 5 rows of the dataset before any processing:\n",
      "              datetime  sourceID  timediff  ZAxisInPossible  ZAxisOutPossible  \\\n",
      "0  2023-03-27 08:14:34        10       0.0              NaN               NaN   \n",
      "1  2023-03-27 08:14:49         4      15.0              NaN               NaN   \n",
      "2  2023-03-27 08:14:56         5      22.0              1.0               0.0   \n",
      "3  2023-03-27 08:15:08         1      34.0              1.0               0.0   \n",
      "4  2023-03-27 08:15:39        12      65.0              1.0               0.0   \n",
      "\n",
      "   YAxisDownPossible  YAxisUpPossible       PTAB  BC  S1  ...  C24  EN  SHL  \\\n",
      "0                NaN              NaN        NaN   0 NaN  ...  NaN NaN  NaN   \n",
      "1                NaN              NaN -1127700.0   0 NaN  ...  NaN NaN  NaN   \n",
      "2                1.0              1.0 -1127700.0   0 NaN  ...  NaN NaN  NaN   \n",
      "3                1.0              1.0 -1127700.0   1 NaN  ...  NaN NaN  NaN   \n",
      "4                1.0              1.0 -1127700.0   1 NaN  ...  NaN NaN  NaN   \n",
      "\n",
      "   SHS  BodyPart_from  BodyPart_to                            PatientID_from  \\\n",
      "0  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "1  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "2  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "3  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "4  NaN          BRAIN        BRAIN  80416a5e946f12b0d3e0fabce7ff76b6c95c2476   \n",
      "\n",
      "                               PatientID_to  BodyGroup_from  BodyGroup_to  \n",
      "0  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "1  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "2  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "3  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "4  6e81762c9c2cf2534a1789063381d4e610184a5b               1             4  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the already encoded data\n",
    "file_path = \"../data/encoded_176398_HEAD.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Data loaded successfully from {file_path}.\\n\")\n",
    "print(\"First 5 rows of the dataset before any processing:\")\n",
    "print(df.head())  # Print first few rows to understand the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cf2dad6e-dc1d-44a1-85c6-6f9f54471a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unnecessary columns.\n",
      "Remaining columns: ['sourceID', 'timediff', 'PTAB', 'BodyGroup_from', 'BodyGroup_to']\n",
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        NaN               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns (based on your latest specification)\n",
    "columns_to_drop = ['datetime', 'SN', 'ZAxisInPossible', 'ZAxisOutPossible', 'YAxisDownPossible', \n",
    "                   'YAxisUpPossible', 'BC', 'S1', 'S10', 'S11', 'S12', 'S2', 'S3', 'S4', \n",
    "                   'S5', 'S6', 'S7', 'S8', 'S9', 'BO1', 'BO2', 'BO3', 'B1', 'B2', 'B3', 'B4', \n",
    "                   'B5', 'HE2', 'HE4', 'NE2', 'HE1', 'HE3', 'NE1', 'SHA', 'HW1', 'HW2', 'HW3', \n",
    "                   '18K', 'FA', 'TO', 'BAL', 'BAR', 'BCL', 'BCR', 'HC2', 'HC4', 'HC6', 'HC7', \n",
    "                   'NC2', 'HC1', 'HC3', 'HC5', 'NC1', 'Na', 'UFL', 'PA1', 'PA2', 'PA3', 'PA4', \n",
    "                   'PA5', 'PA6', 'SP1', 'SP2', 'SP3', 'SP4', 'SP5', 'SP6', 'SP7', 'SP8', 'BL8', \n",
    "                   'BR8', 'UFS', 'HEA', 'HEP', 'SC', 'PeH', 'PeN', 'FS', 'FL', 'BY1', 'BY2', \n",
    "                   'BY3', 'BL', 'BR', 'HE', 'BL4', 'BR4', 'BL1', 'BR1', 'BL2', 'BR2', 'L7', \n",
    "                   'L4', 'H2L', 'N2L', 'H1U', 'N1U', 'He1', 'He2', 'TR1', 'TR2', 'TR3', 'TR4', \n",
    "                   'TR5', 'TR6', 'MR', 'ML', 'BL5', 'BR5', 'C24', 'EN', 'SHL', 'SHS','BodyPart_from', \n",
    "                   'BodyPart_to', 'PatientID_from', 'PatientID_to']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(\"Dropped unnecessary columns.\")\n",
    "print(\"Remaining columns:\", df.columns.tolist())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1397fae-e907-4020-b74b-3d16be7a0707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sourceID  timediff       PTAB  BodyGroup_from  BodyGroup_to\n",
      "0        10       0.0        0.0               1             4\n",
      "1         4      15.0 -1127700.0               1             4\n",
      "2         5      22.0 -1127700.0               1             4\n",
      "3         1      34.0 -1127700.0               1             4\n",
      "4        12      65.0 -1127700.0               1             4\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values with 0 in the DataFrame\n",
    "df.fillna(0, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1904656c-1090-4e8a-97d3-8f53cb5a1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target (sourceID)\n",
    "X = df.drop(columns=['sourceID'])\n",
    "y_sourceid = df['sourceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "78bdf0b2-71d9-4890-bdc5-603a45a1c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few one-hot encoded 'sourceID' values:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Shape of one-hot encoded 'sourceID': (4501, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode 'sourceID'\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_sourceid_encoded = encoder.fit_transform(y_sourceid.values.reshape(-1, 1))\n",
    "original_sourceids = encoder.categories_[0]\n",
    "# Print the first few rows of y_sourceid_encoded to confirm one-hot encoding worked\n",
    "print(\"\\nFirst few one-hot encoded 'sourceID' values:\")\n",
    "print(y_sourceid_encoded[:5])\n",
    "print(\"Shape of one-hot encoded 'sourceID':\", y_sourceid_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ce7e72e-eb07-4a28-8e1d-f55f0755d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ff40f546-c53a-4ede-882c-6a475efc375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sequence length of 5 for Transformer input\n",
    "sequence_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "655d282c-1adf-424f-8888-2f2032944cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(target[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X_sequences, y_sequences = create_sequences(X_scaled, y_sourceid_encoded, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6f863f69-8264-4adc-834e-00ba1562ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder model\n",
    "def transformer_model(input_shape, output_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Embedding layer to transform input to higher dimensional space (if needed)\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    \n",
    "    # Multi-head attention layer\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
    "    \n",
    "    # Add & Norm\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
    "    \n",
    "    # Feedforward layer\n",
    "    ff_dim = 256  # adjust this dimension as needed\n",
    "    x_ffn = Dense(ff_dim, activation='relu')(x)\n",
    "    x_ffn = Dense(x.shape[-1])(x_ffn) \n",
    "    \n",
    "    # Final classification layer (softmax for multi-class)\n",
    "    outputs = Dense(output_dim, activation='softmax')(x[:, -1, :])  # Only last timestep output\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "108f88fd-26fb-4358-bf34-fdfa2b755cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "input_shape = (sequence_length, X_scaled.shape[1])\n",
    "output_dim = y_sourceid_encoded.shape[1]\n",
    "model = transformer_model(input_shape, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4fed0869-09f8-467d-9320-851b7c1a1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ccf9d9de-9dae-49e4-819a-e1cf0c2e777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "140/140 [==============================] - 8s 14ms/step - loss: 2.1379\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.9303\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8723\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8655\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8431\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8391\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8328\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8285\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.8331\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.8250\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.8208\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.8115\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.8059\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.8068\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7949\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7881\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.7843\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7831\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7755\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7656\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.7494\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7563\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.7501\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 1.7342\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.7228\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 1.6844\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 1.6675\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 1.6698\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 1.6486\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 1.6271\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_sequences, y_sequences, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "400533ec-23a9-4c61-9526-c5405d77724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on training data\n",
    "predicted_sourceids = model.predict(X_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "866043f9-78b9-4156-97fd-d4c4b9823bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted probabilities back to class indices\n",
    "predicted_classes = np.argmax(predicted_sourceids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b74dde7-84af-4727-b4ad-9c317cc0ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few predicted sourceIDs:\n",
      "[[5]\n",
      " [5]\n",
      " [5]\n",
      " ...\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot back to original sourceID using the encoder\n",
    "predicted_sourceids_final = encoder.inverse_transform(predicted_sourceids)\n",
    "# Print results\n",
    "print(\"\\nFirst few predicted sourceIDs:\")\n",
    "print(predicted_sourceids_final[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c533e0e-6323-4f2a-9801-37e48cc59d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_6' (type Functional).\n    \n    Input 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'model_6' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=int32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Test prediction with tokens\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sample_input_sequence \u001b[38;5;241m=\u001b[39m X_sequences[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Use the first sequence for demonstration\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m predicted_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_with_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_input_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted sequence with start and stop tokens:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_sequence)\n",
      "Cell \u001b[1;32mIn[126], line 10\u001b[0m, in \u001b[0;36mpredict_with_tokens\u001b[1;34m(model, input_sequence, start_token, stop_token, max_length)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Use the current sequence to predict the next token\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     current_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predicted_sequence[\u001b[38;5;241m-\u001b[39msequence_length:])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     next_token_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(next_token_probs)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Append the predicted token to the sequence\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_896z7cp.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\z004uyxr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_6' (type Functional).\n    \n    Input 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'model_6' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=int32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Prediction function that respects start and stop tokens\n",
    "def predict_with_tokens(model, input_sequence, start_token, stop_token, max_length=100):\n",
    "    # Initialize the output sequence with the start token\n",
    "    predicted_sequence = [start_token]\n",
    "    \n",
    "    # Predict step-by-step until we hit the stop token or reach max length\n",
    "    for _ in range(max_length):\n",
    "        # Use the current sequence to predict the next token\n",
    "        current_input = np.array(predicted_sequence[-sequence_length:]).reshape(1, -1)\n",
    "        next_token_probs = model.predict(current_input)\n",
    "        next_token = np.argmax(next_token_probs)\n",
    "        \n",
    "        # Append the predicted token to the sequence\n",
    "        predicted_sequence.append(next_token)\n",
    "        \n",
    "        # If the stop token is predicted, stop generating\n",
    "        if next_token == stop_token:\n",
    "            break\n",
    "    \n",
    "    return predicted_sequence\n",
    "\n",
    "# Test prediction with tokens\n",
    "sample_input_sequence = X_sequences[0]  # Use the first sequence for demonstration\n",
    "predicted_sequence = predict_with_tokens(model, sample_input_sequence, start_token, stop_token)\n",
    "print(\"Predicted sequence with start and stop tokens:\", predicted_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "59c29ed2-9b12-4256-a3db-708510c68af1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sourceids\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert the predicted sequence to sourceIDs\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m predicted_sourceid_sequence \u001b[38;5;241m=\u001b[39m map_tokens_to_sourceids(\u001b[43mpredicted_sequence\u001b[49m, encoding_legend)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted sourceID sequence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_sourceid_sequence)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "# Map predicted token sequence to original sourceIDs using the legend\n",
    "def map_tokens_to_sourceids(token_sequence, encoding_legend):\n",
    "    sourceids = [encoding_legend.get(token, 'Unknown') for token in token_sequence]\n",
    "    return sourceids\n",
    "\n",
    "# Convert the predicted sequence to sourceIDs\n",
    "predicted_sourceid_sequence = map_tokens_to_sourceids(predicted_sequence, encoding_legend)\n",
    "print(\"Predicted sourceID sequence:\", predicted_sourceid_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35aed398-e9d2-4d89-bb71-adb8cfda4ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few predicted sourceIDs:\n",
      "['MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_257', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_FRR_257', 'MRI_FRR_257', 'MRI_FRR_257', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_257', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_CCS_11', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264', 'MRI_FRR_264']\n",
      "Predicted sourceIDs saved to 'predicted_sourceids_final_1.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Function to map one-hot encoded predictions back to sourceIDs\n",
    "def map_onehot_to_sourceid(onehot_predictions, encoding_legend):\n",
    "    sourceids = []\n",
    "    for prediction in onehot_predictions:\n",
    "        index = np.argmax(prediction)  # Find the index of the highest value\n",
    "        sourceid = encoding_legend[index + 1]  # Map back using the legend (1-based index)\n",
    "        sourceids.append(sourceid)\n",
    "    return sourceids\n",
    "\n",
    "# Encoding legend mapping (this is just a sample, adjust to your actual encoding legend)\n",
    "encoding_legend = {\n",
    "    1: 'MRI_CCS_11',\n",
    "    2: 'MRI_EXU_95',\n",
    "    3: 'MRI_FRR_18',\n",
    "    4: 'MRI_FRR_257',\n",
    "    5: 'MRI_FRR_264',\n",
    "    6: 'MRI_FRR_3',\n",
    "    7: 'MRI_FRR_34',\n",
    "    8: 'MRI_MPT_1005',\n",
    "    9: 'MRI_MSR_100',\n",
    "    10: 'MRI_MSR_104',\n",
    "    11: 'MRI_MSR_21',\n",
    "    12: 'MRI_MSR_34'\n",
    "}\n",
    "\n",
    "# Map predicted one-hot encodings to original sourceIDs\n",
    "predicted_sourceids_final = map_onehot_to_sourceid(predicted_sourceids, encoding_legend)\n",
    "\n",
    "# Print the final predicted sourceIDs\n",
    "print(\"\\nFirst few predicted sourceIDs:\")\n",
    "print(predicted_sourceids_final[:32])\n",
    "\n",
    "# Optional: Save the predicted sourceIDs to a CSV file\n",
    "output_df = pd.DataFrame(predicted_sourceids_final, columns=[\"Predicted SourceID\"])\n",
    "output_df.to_csv(\"predicted_sourceids_final_1.csv\", index=False)\n",
    "print(\"Predicted sourceIDs saved to 'predicted_sourceids_final_1.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcd71f-98b4-49f3-941b-7af27940e924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a6645-d76c-4788-85ea-72e762f61eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4e5f1-5e1f-4db5-8b9f-a8bd49b2a915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
